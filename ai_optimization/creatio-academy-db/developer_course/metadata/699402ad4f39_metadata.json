{
  "content_id": "699402ad4f39",
  "content_type": "pdf",
  "title": "Creatio Developer 12",
  "source_file": "/mnt/c/Users/amago/Desktop/InterWeave Documents/Creatio/Developer Course/transcripts/Creatio-Developer-12.pdf",
  "processed_content": {
    "text_content": "--- Page 1 ---\n\n \n  \n  \nSpeaker 1\n \n Today is session number nine of our development on Creature platform guided learning. And today we will continue \nto study server side and we'll move on with integration tools. So yesterday we finished with our own web service. It \nwas made at creation site, was made with the help of C Sharp sources and we programmed it, we saved it in file \nsystem. We used Visual Studio to develop this web service. So we used our examples. Now you know, okay, now you \nknow how you can make your own integration tools. But in general, so integrations will require much more entities \nand will require much more tasks to exchange data. So it will be really hard for you to write a web service for each \ndata transfer that you need in your system.  \n  \n  \nSpeaker 1\n \n So what we'll study today, how to use standard platform level tools to operate with data with the help of HTTP \nqueries. And we will discuss and I will show you examples of how to work with standard tools. And they are all data \nprotocol and data web service. Also I plan to show you how to call third party web services with the help of no code \ntools, with the help of settings for web services and call web service item. And at the end of the session I want to tell \nyou about Clio tool, Clio Commons. You will understand what is this, how it can be used, why you need some \nadditional tools. So we will discuss a bit more about system maintenance delivery and if you have any questions, I'll \nbe really happy to hear and to answer them.  \n  \n  \nSpeaker 1\n \n So don't be shy, ask any questions if you feel something that you need to know and let's move on. So integrations \nwith data tools. First of all I need to show you general integration capabilities that we have on board. Go to \ndevelopment guides integrations options and here you can see standard options that we have. We already studied \ncustom web service option and it offers us possibility to program anything we need to ask for data, to make \noperations with files, to use any libraries. But this approach obviously requires some programming at creation site. \nAnd also this approach requires programming at third party site in order to normally correctly call such service and \nto get response data parse such response. So I just want to say that in general it's quite expensive approach if you \nneed to do a lot of different operations.  \n  \n  \nSpeaker 1\n \n As you can see we have other options to integrate with creation. We have two options for data transfer such called \nCRUD operations which means create, read, update and delete. So standard simple operations that you may need to \nwork with your data and to organize. Possibility to read some data for third party app or to make some inserts, \nupdates or deletes in creation by commands from other applications. And we have two different options for this. \nOne is called Data Service, another is called Odata. And Odata is quite common because it was designed by \nMicrosoft and it's possible to find Odata clients as third party sources. There are a lot of tools that understand how \nto work without data. So developers of Creation decided to support this type of client. And data service is much \nmore unique.  \n  \n  \nSpeaker 1\n \n It's very specific to creature, but it offers you more options, more possibilities, more complicated calculations. And \nthat's why data services used for creation of client side and data service in general is more powerful than ODATA \nand more complex to program. So I will show you both ODATA and Data Service. You will see how it works. Also, it's \nworth it to mention that we have another integration option to run business processes. So you can use process \nengine service web service for starting or continue execution of business processes the same way how you can do \nit from creation client side. Physically, this web service is the only one to handle processes. And when we run \nprocesses from inner application. Let me remind you how we did it.  \n \n\n--- Page 2 ---\n\n \n  \nSpeaker 1\n \n We had the class on Freedom UI section, we can open its page and then we made an action to calculate average \nprice with the help of business process. You remember we did this calculation, we started process, now we have \nsome results, average price in dollars. Then we save it or close it. And that's how we finish our process. So physically \nwe did some calls to third part to process engine web service. Here you can see it. And the same calls with the same \nparameters can be done with third party applications. So it's possible to run processes from 30 third party. And of \ncourse in this case you need to pass authentication first. And we did it yesterday with the help of Postman tool. You \nremember we had the Postman authentication, we had set of authentication cookies. Okay.  \n  \n  \nSpeaker 1\n \n So if interested, you can just watch yesterday video and get more details. So today we'll focus on data transfer \nintegration options. And I would like to start from OData because it's easier, it's more friendly for beginners and it's \nquite easy to start from scratch. So what it is, this is a data transfer protocol which is supported at creation. We have \nall documentation about it. So for all data we have documentation explaining how to use it. And in general you need \nto know that creation supports OData 4 and OData 3. Unfortunately, OData 3 is not supported in packages. So it's \nnot supported for objects that are saved in packages compiled as Separate assembly. So it means that for your \nODATA integration, probably it's better to focus on OData 4 from the beginning.  \n  \n  \nSpeaker 1\n \n We have a lot of documentation about it and if interesting you can find much more. And we have examples, we have \nreferences. So I prefer to show you something really useful. This article, it explains some general basics about how \nto use OData. We will try to make some examples and first you need to know that ODATA operates with the help of \nData Model. So it means it respects all existing objects, their columns, their names and so on. So when you operate \nwith OData, as well as when you operate with Data service, it uses Data Model. So it uses information about existing \nobjects, columns, references and access rights restrictions.  \n  \n  \nSpeaker 1\n \n Okay, so depending on what operation you need, you have to select the proper HTTP method, Get is used to select \npost for inserts, patch for updates, and HTTP Delete is used to perform physical delete operation. I will show you a \ncouple of examples and also you need to know that we have a lot of interesting documentation samples here. And \none of the good ones is creation API documentation hosted at Documentor, get postman. Com. This is one of the \nbest sources that you can find for OData. I plan to show you examples with OData 4. As you can see, first of all, we \nhave to make authentication correctly. Then we can do different queries and different examples. So depending on \nyour task, you may find a corresponding sample here. And also we have a lot of samples to make different filters.  \n  \n  \nSpeaker 1\n \n You see, for different filters there are special expressions in let's say ODATA language. And so you can find a lot of \nexamples here. Even batch queries Supported Batch queue means running single query with several parameters. \nAnd each parameter explains to a system how to run a particular operation. So it can be useful if your plan is to run \nmany data operations with one single query. So batch operations are also supported. But we can do it. Let's not go \ntoo far. And I understand that probably not all of you will start your integration at all. And this is something that you \njust need to know and let's say get familiar with it. You will see how it works. So let me show you examples. My plan \nis to make some selection of data. We have some examples of data records.  \n  \n  \nSpeaker 1\n \n Let's read data from our reality object, but with the help of all data. First of all, I will use integration tool, I will use \n\n--- Page 3 ---\n\nPostman app and my yesterday cookies are not working anymore. They will not help me to run queries. I can check it \neasily so we can Try to run our web service and as you can see we have 401 not authorized. It means that our \ncookies are related to expired session. So providing such cookies we will not be able to use any business methods \nany business logic methods of creation web services. So we have to get new cookies. I prefer to clear previously set \ncookies. We go to perform login operation again. Yesterday we discussed how to do this. We use special URL to all \nservice and its login method inside of a root part of our application.  \n  \n  \nSpeaker 1\n \n We provide login and password. No any special data, no any special headers. You may find some information here \nlike authentication and some accept content type for C session. But it turns out to be not necessary to perform \nauthentication successfully. So let me show you here we have some hidden headers made by postman like accept \ncontent type, application JSON and so on. But so I prefer to keep it as is by default. And we have login and \npassword. Originally we have no cookies. So let's try to get new session for us. Yes, we got it. 200 no errors. So \ncurrently we have set of cookies enough for us to perform inner queries. Okay, we can create new query and our \ntask. Let's keep it easy and keep it simple. So we will try to read data.  \n  \n  \nSpeaker 1\n \n We will have to make a selection of data records and we will make it get HTTP query. Let's do this. So let's go to \npostman, create a new get query. We have to use our address of our app with 0 alias here and then we can look at \nthis example or we can look at this document or get postman.com examples. So we need to do selection. And our \npart for odata web service is odata here. So it's a name of odata endpoint then/in odata4 we should use just entity \nname here. It's not obvious that collection one is entity name. And here you can see that it's also not so obvious, but \nmaybe you can find examples. Yeah, here you can see an example. So it will make it clear how we can do this. So I \nwill use an example with my USR realty.  \n  \n  \nSpeaker 1\n \n If I provide no any parameters, system will try to read all of the data with all of the records, all of the columns. Let's \ntry to do this and run send for get queries we do not need to use BPM CSRF protection. So for get queries, no cross \nsite request forgery protection needed. And you see it took significant time, almost six seconds to run. And as a \nresult we have Some JSON body with different data records about our reality record saved in database. As you can \nsee all of the columns, a lot of unnecessary data. But that's how it works. If we provide no special parameters. Now I \nwill show you how we can make it more interesting and more useful. We can use different parameters in our script in \nour query.  \n  \n  \nSpeaker 1\n \n And let me show you for example parameters for selecting data collection instance selected fields. So here I can see \nan example and it means dollar select so question dollar select and then we have columns with comma separated \nvalues to get necessary columns. So I'm using this example, you can use this example and let me show you how we \ncan do it. So question mark to switch to parameters Dover select is parameters specifying column names that we \nplan to use. Don't forget we have to use column codes, not titles USR name USR price USD maybe created on. So if \nyou want you can get more. It's possible to use lookups in order to get corresponding names of type or name of a \nperson who created the record. But now I try to keep it simple. So this is example of how we can run queries.  \n  \n  \nSpeaker 1\n \n You see only requested columns. Now here and we can see all of the data. We can do some limitation. So we can \nuse and another parameter dollar top three for example. And when we do such selection, it will read only top three \nrecords for us. You see on the top three records you can use sort, you can use filter. We can use x order by in order \nto organize some sorting. We can use special parameters to select only one specific record but filtered by ID a lot of \nother options. So if necessary you will be able to do this. And I try just to keep it simple and quite useful for you. So \n\n--- Page 4 ---\n\nhere is an example of a get query to read some data. So you can try to do it even in your browser.  \n  \n  \nSpeaker 1\n \n In case if you will try to run such query in your browser, you do not need authentication because usually your browser \nis already authenticated in creation and you keep running session running pages of your creation in your browser. \nAnd that's why you don't usually need to prepare separate separate authentication for it. Okay, I think for selection it's \nquite clear. So let me show you how you can do insert data. I need to use almost the same set of parameters but for \ninsert. As you can see here we have post to add data. Let's do this. We can also look at examples for post and our \nURL will be quite simple. We will just provide post and this URL which includes our website zero application Alice \nOData is the endpoint for OData Web Service.  \n  \n  \nSpeaker 1\n \n Then usr realty is also part of endpoint and it gives information to data what exact object you plan to operate with. \nThen I have to look at body row JSON and we have to provide some data for example USR name. This is mandatory \ndata from all data for integration it will be our name USR price USD okay, so you can see we have some data here. If \nwe try to run a post query without CSRF settings we will get 403 because for post query we must perform BPM CSRF \nheader we must put corresponding cookie value. Please carefully copy cookie value including some dots if they \npresent. So it's important in this case our insert will work. Okay? No, it tells that comment doesn't exist. Okay, it was \nmy fault because common name is USR comment. Okay, everything is working.  \n  \n  \nSpeaker 1\n \n Now we can go to our main app, sort by date of creation and we will immediately see that our data was added and \nwe can also check column values. Here you see price was added, we see column was added correctly. But what we \nreally interested you can see the type and offer type were set by default. It means our object model worked well for \nus and moreover our object model also supported all event handling provided with help of start signals. Now you \nsee three realty visits were already planned for upcoming days. So all business logic that was designed and \nprogrammed with the help of event handling with the help of start signals it will work for ODATA as well and server \nside handling like we did to validation for very big prices will also work. Now let me show you how it can look.  \n  \n  \nSpeaker 1\n \n So let's try to add very big number and it will be more than 1 billion. So we will see how system will react on this \nattempt. Now you see we have a quite rude error and this is error 500 internal error. But we have error text which \nmeans we intentionally erased such exception. We provided error message text of what is wrong and of course \nphysical insert was not done so we can read data, you see no new records created. So this is example how you can \nuse old data for your tasks and it will be really attractive for relatively simple tasks for your future integration needs \nwhere you need to transport not so many data records. If your task is to transport millions of rows, possibly such \napproach with running separate queries for each record will be not very effective, not very efficient.  \n  \n  \nSpeaker 1\n \n In case if your task is to transport huge amounts of data, you have the only one option. This is your own \nprogramming of such data and your own parsing your data structures and your own database direct operations and \navoiding use of object model. Because when you use object model, you also support all of the object events. It \nworks not so fast. And for example, when we did insert with the help of postman, it took almost 180. No, in total it \ntook a bit longer. You see, we have some additional cost for preparation of the query. So it took 300 milliseconds. \nAnd it's important because if your task is to transport like 1 million of data rows, if you spend 300 milliseconds for \neach one, it means you will wait for several days and this speed probably will be not suitable for your customers.  \n   \nSpeaker 1\n\n--- Page 5 ---\n\n  \n So you have to search for a better solution. So in case of big number of records to process, in case of very, let's say, \nhard speed requirements for your solution, the only suitable option is your own web service with your own data \nformats, your own direct database management without use of object model. But in simple real life scenarios, I think \nall data will work well for you. And it's relatively easy because you see it's not so hard to build such query to run it \neven when your third party app is used. So you can do such programming. And also you will get response data in \nJSON string, so you can easily parse it, you can easily extract corresponding results that you may need. Here you \ncan see JSON objects and you can also get corresponding values from here. So it's very suitable for beginners.  \n  \n  \nSpeaker 1\n \n And for some tasks I think it will work perfectly. But for some other tasks you may find that all data is not enough, \nmaybe because of hard load conditions you will finally realize that our data is not going perfect with hard, I would \nsay hardwood big amounts of data. Maybe you will need some more complicated scenarios with reading data and \nperforming some calculations like preparing reports and running it with third party app. And you will need some \naggregation, some complex filtering. In this case, all data probably will be not the perfect solution. And data service \nmay work better. For data service is created by creature developers, not by Microsoft. And this is unique to creature \ntool.  \n  \n  \nSpeaker 1\n \n So it's appropriate way of operating with data using creature server side, it can do all the same operations like \ncreate, read, update and delete data and but it can do it a bit more efficiently. And also it supports different filter \ncondition macroses and it's much more rich when you need to select data from different tables, perform some \naggregations, perform some complex filtering. I will demonstrate what data service can do. And first of all I need to \ntell you the data service is mainly Used by inner creation client side pages. Each time when you operate with any list \nor edit page, you will see data service web service queries. You will also see that payload for that queries. It means \narguments that you need to transport. Payload is quite complex. You see more than hundred of different settings \nand if you preview.  \n  \n  \nSpeaker 1\n \n So if you view source, you see a lot of settings and parameters that can be passed as arguments for data service. \nBut it also has a response with a JSON. So now you see JSON string which can be parsed and such JSON data not \nso hard to operate with. You can easily get corresponding values out from your results. So Data service web service \nmaybe can be suitable in case if for some reasons old data doesn't work for you as you expect. I will show you \nexamples of data service but first I wanted to mention that it's used inside of creatio pages. So data service was \ndesigned for inner creation data operations with client side. All lists and all edit pages are using data service to get \nor to modify, insert, update any data record.  \n  \n  \nSpeaker 1\n \n So in documentation you will find that data service is promoted as integration tool. So it's a restful service. You can \nuse third party to compose queries for it. And here it's promoted and advertised like an integration tool. But in reality \nit's not so integration oriented, but it is say platform UI oriented. Because all UI pages are working with the help of \nthis web service. I will show you some advanced features that this web service supports and let me hide some \nunnecessary columns. So my plan is to show you special types of columns called aggregate columns and also a bit \nlater aggregate filters. So aggregate column can make some calculation over connected data records. And such \nconnections will be done with the help of main record. Let me show you what I'm talking about. So each reality \nrecord may have number of visits inside.  \n   \nSpeaker 1\n\n--- Page 6 ---\n\n  \n Recently created records are having more visits because we already had automatically creation for them. But also \nwe have. Oh, we don't make any action to add the data director here. Okay, so we have some examples which already \nhave created data records in visits detail. And for each reality record we have number of visits, connected detail \nrecords. So we can make a career column. We can make an aggregate column which will simply calculate number of \nconnected records. This is one of the easiest possible aggregate columns that we can make. So let me show you \nhow you can do this.  \n  \n  \nSpeaker 1\n \n Add the columns and instead of working with traditional set of columns we have in main object you can go to related \nobjects and then we will see all objects that are available for us according to lookup columns from main object and \nalso we will see reverse joins. We will see other entities that have lookup columns pointing to reality. In my case this \nis realty visit. We have different options how to select data from it. And in last versions we have also advanced \nexamples like reading top one record. For example, we can read top one comment sorted by date of creation. Or we \ncan see top one customer who is specified in recent visits and so on. In my case I try to keep it simple. Let's look \nonly at number of records of connected visits and click select.  \n  \n  \nSpeaker 1\n \n It's also possible to specify special conditions to select data. For example, we can only calculate number of records \nthat are in future or only visits where contact is specified. So you can do different conditions here. In my case I also \ntry to make it easy and calculate total number of visits. And we can make the caption here visits count. So this visits \ncount will be our title for new created aggregate column. Then we click save and now you see new column which \nshows us some data. And for each separate reality we have some calculation. It's interesting to mention that this \ntype of calculation is also performed with the help of data service. Moreover, such calculation is performed with the \nsame query where a main data record is selected.  \n  \n  \nSpeaker 1\n \n So if you reload the data using this update refresh button, you see only one query was executed and if you go deeper \nin payload you will see that our column for calculation of aggregate number is also represented to the standard \ncolumn. Here we have some column path for it, some setting for Type of aggregation. Aggregation Type 1 means \ncount and that's how system knows what to calculate and returns as some calculated number. This it was example \nof aggregate column and it can be really useful. And you should understand that this selection is not performed \nfrom reality. This column is obtained as a result of subquery from reality visits. And I want you to see one more \nfeature called folders and here we can make additional folders select and add the new folder here.  \n  \n  \nSpeaker 1\n \n So in general folders work here like search folders in your outlook. So here we can specify some name and the filter \nconditions that will be useful for us to select only some searching data, not all of the data from our list. Let's call it \nthree plus visits. So let's imagine for some reasons we need to look at realty records where we have three and more \nvisits created. We are not interested in realty records with no visits. So we can make such a name here, save it. Then \nwe can provide filter conditions for this folder. So now I'm planning to show you so called aggregate filters. We \nalready saw aggregate columns and you understand that they represent result of subqueries but calculated with the \nsame main query.  \n  \n  \nSpeaker 1\n \n And aggregate filters will be used for selecting data applying conditions on connected records, not on reality data \nbut on connected records. In my case I plan to select only reality data where this visits count is greater or equal to \n\n--- Page 7 ---\n\nthree so we can make condition and here we have to select connected entity. So not just dropping down here \ncontents of reality columns. We have to click on this plus in order to select connected entity. In my case connected \nentity is real and the aggregation type will be just quantity and also we have alternative options like maximum or \nminimum date for creation or modification. If we had integer or decimal values there then it's possible to calculate \naverage price maximum or minimum.  \n  \n  \nSpeaker 1\n \n So in my case I will just do quantity calculation select and we have condition count greater or equal three that will be \nour filter condition. We also can make additional filters here like counting only visits in future or counting only visits \nwith not empty comment. So whatever you think it will be useful you can do here. Then we save it and that's how we \nsee result of this filtering. So all data shows us all reality records. This search folder shows us only records which \nfollow corresponding filter conditions. Such filters are called aggregate filters and we can now go again to network \nand reward the data to see that our payload also has special filter condition. And this filter condition includes \ninformation that we use aggregate function.  \n  \n  \nSpeaker 1\n \n We use count for our aggregation so it will do selection only of records where some sub select some count of \nconnected data is greater than certain right expression and we have just value three here. So my example is to \ndemonstrate that data service web service is capable not only to read plain data from the data sections, but also it's \ncapable able to calculate aggregate columns and to use aggregate filters and you can use data service for your \nintegration. But I think it's really hard because you will need to have a good make already good made examples to \nmake it work. So if you make corresponding queries in your browser then you can steal all necessary parameters. \nLet me show you how we can do this. We can copy request URL from our query that we spotted in our network tab.  \n  \n  \nSpeaker 1\n \n Then we go to postman create new actually you should be careful because data service is usually working with post \nqueries only. So we go to postman. Regardless of the operation we will use post query and paste this URL should be \ncareful. Okay Paste URL we have a huge body. We have go to payload view source select everything copy then we go \nto body here this is row JSON and we paste this big body it's really hard to analyze it so we can use beautify tool to \nsee it in a more structured way. So now you see we have a lot of options here that are used by data service and \nrequired here to be present. And as you can see I did not type them manually. I only used existing example from my \nbrowser console.  \n  \n  \nSpeaker 1\n \n This is a post clear so we obviously will go will fail into CSRF protection if we do not care about it. So BPMCSRF \nheader and corresponding cookie value you should get it carefully copying full value and pasting it here. Now we will \nsuccessfully run our query, we have some valid response JSON body and we see set of records, we see set of data \nand in general if you run something like this from third party app then you'll be able to parse your data and you'll be \nable to analyze it and get corresponding numbers or other columns if you need it. Adrian is asking is folder the only \nway to go to Advanced filter in Freedom ui? Yes, Currently we don't have any separate advanced filters for data \nselection, so developer decided to keep it saved into folders.  \n  \n  \nSpeaker 1\n \n In Classic UI we had an option to keep such code advanced mode and make this filtering like flying in the air without \nlanding anywhere in your system. But I personally think that this kind of advanced filter is not so good because once \nyou take time to build it, once you make complex conditions there is a highly likely situation then you will need it to \nsave. So developers in Freedom UI decided that no advanced filters anymore. If you need some complex filtering, \njust mentally prepare yourself to save it as a folder. It's not a big deal, not a trouble. And such folders usually have \nquite strict permission settings. So when you create a folder only your user will see it so it will not create too much \n\n--- Page 8 ---\n\nof garbage records seen by anyone. Only your user will see such records.  \n  \n  \nSpeaker 1\n \n If you don't like it you can also remove it. So I think it's not a problem. Thank you Adrian for your question. And yes I \nagree we have some changes between Classic and Freedom UI and it looks like such changes were discussed so it's \nnot a real decrease of some important functionality. Thank you Adrian. So this example shows that Data Surveys is \nmuch more capable in comparison with ODATA because you can use more complicated calculations for columns for \nfilters and everything is going with just a single query. How we did here and demonstrated in Postman that it works \nperfectly in real life. Your integration will include not but one or two queries in real life I think you will need tens or \neven more queries to start. So it means that you will have series of different queries.  \n  \n  \nSpeaker 1\n \n You will need to remember data and save it somewhere. And in general it requires some quite strong professional \ndeveloper skills and architectural understanding of what you are doing. In general, I recommend you to run queries \nthat will not return you millions of records. It's better to operate with data using some portions and both ODATA and \ndata service have their own limitation. So we can find some limitation. Number of requests is unlimited but \nintegration options. I saw some information about it that we have a limitation about 20,000 of records per one \nselection and the same limitation will be applied for data service. This is limitation for OData and data service has \nvery similar limitation. But I just suggest and recommend you to operate with data with some smaller portions.  \n  \n  \nSpeaker 1\n \n Keep some logging by yourself so it will be easier for you to detect and understand how actually it goes and do you \nhave any serious errors in your integration. So it's like a programmer task, but it's possible and in complex projects \nwe also do this and it works well. So let's move on. We already studied how third party app can operate with creatio \ntools and odata and data service are already present at creatio server side so they are already prepared for you. So \nyou only have to program at third party application to correctly call such tools and it will work for you. Now I wanted \nto show you an example how we can run third party web services from Creature and also how to do it with no code \ntools because no code is really attractive.  \n  \n  \nSpeaker 1\n \n It takes very little time to develop and gives quite quick and valuable results. Let me show you. So let's imagine we \nhave Creature app, we have different sections, data and so on and we have some third party application that we \nwant to call and to use its data to perform some data transfer. Let me show you some example of it. We have a node \nwith REST API samples so we can use something like this. Let me show you. This is a REST API URL call that we can \nsend. This is a GET query. You can easily do it in your browser. Luckily it does not require any authentication. So it's a \nGET query performing with some kind of URL. No initial arguments but we have some response.  \n  \n  \nSpeaker 1\n \n JSON body this JSON body is also shown here for us and this JSON body represents some prices and I need to tell \nyou some physical sense of it. ID bank is one of the banks in Armenia and they sell gold bars, gold plates starting \nfrom 1 gram gold to up to 12 kilos gold, big gold slab and you see their prices are in local Armenian currency, \nArmenian drums. But in our case it's doesn't matter so we only want to practice here and also I want to show you \nsome additional example. Not only just get couple of data values from third party app but also to show you how you \ncan use no code tools to process collections and to get sets of some data records, how to store it, how to operate \nwith it.  \n   \nSpeaker 1\n\n--- Page 9 ---\n\n  \n So let's imagine we have a task to regularly get gold prices from this URL, from this API, save it in creatio and make it \npossible to run multiple times and correctly update such prices. I will use only no code tools for it and you will see \nhow we can do this. Also you may reproduce it just during today's session. So let's start. We have URL and it's nice if \nwe have some description of this URL. So generally we have it but in my case it will be really simple so I did not really \nneed it. But normally when you work with some kind of integration you will have this kind of explanation of how to \ncall corresponding query, how to transport some parameters rate go. Okay, now you see example of query, you can \nsee parameters, you can see requests and so on.  \n  \n  \nSpeaker 1\n \n And in my case so I can also share with you this is kind of documentation but the most important we need example \nof call which works for us. Luckily we don't have any special protection, security or authentication necessary for this. \nYou may also find a lot of other sources with similar functionality like currency exchange websites, like weather \nforecast websites, like other regular date that could be commonly interesting for people. It's usually shared without \nany special restrictions. In my case this doesn't require any parameters, any input arguments. So we can do it quite \nsimple and I think that simple example is better for beginners just to get started. So we have this URL and then I will \nexplain how we can work with it. First of all we need to go to studio workplace and find web services section.  \n  \n  \nSpeaker 1\n \n We will properly register our new third party web service here and then we'll be able to call this web service from our \nbusiness processes with the help of call web service item. This will not require actual development skills, but it \nrequires some engineering knowledge and understanding of HTTP queries and HTTP methods type and just a bit of \nunderstanding of JSON string and you will see that it's not very difficult. So let's do this add new web service when \nwe Created system uses current package system settings. So when we provide an example of a full web service \nURL, it parses it and creates corresponding web service setting and tries to save it. We need to take care about the \nproper package to save. Now you see some phantom packages which we can't really find in our configuration, so \nlet's ignore them.  \n  \n  \nSpeaker 1\n \n This is classic package because our current package system setting points to it. But my plan is to save our data to \nfreedom UI realty package. Let it be here. This URI is like a main part which was extracted from our URL and it will be \nused as a like base part of our web service and then we can have many different methods. Method addresses will be \nadded to our main web service URI address. The code is generated by app so let's call it something like gold bar \nservice name will be displayed and the code will be used for configuration saving into a package. Finally, we will \nhave a special type of item saved directly to the proper package. So you don't need to care about how such setting \nwill be saved in our configuration.  \n  \n  \nSpeaker 1\n \n This will be saved as special metadata directly to the package. And we have a method here, so let's save it first. Now \nyou see configuration section and let's go to all items. You will see new type of item called web service and it's \nalready saved in our package. So all you can do is to open its metadata. You will see some low level text definition of \nthe setting like addresses and other settings and so on. But this is low level setting. You just need to remember that \nit will be saved in our package so you don't need to care about special transporting of it. Okay, we continue to do our \nsetup. System was capable to automatically parse our URL and get web service main part and method part and you \ncan see it's by default. This is a get method. Let's look at it.  \n  \n  \nSpeaker 1\n \n And in general one web service may have many methods so you can register them manually in order to use different \nfunctionality of the same web service. Get method the content type is JSON and response timeout is 5 seconds by \n\n--- Page 10 ---\n\ndefault, 5000 milliseconds means 5 seconds, no authentication necessary. And name is for display, code is for \nmetadata to save and method address is the most important property here because it represents exact part of the \nURL which will be used to add and make full. So when we do this we will make foo method address in our we have a \nfull method address in our lab service and this part was automatically parsed here. You can also type different types \nof Parameters like method parameter, method query value and also it's possible to transport additional data values \ndepending on the type of request you use.  \n  \n  \nSpeaker 1\n \n If you use get query like in our case you only can use method address parameters inside of this URL. If you use post, \nit's possible to fill in post body request body and it helps to get much more possibilities to transport different data \nvalues as arguments to your web service. In my case I have no request parameters at all, but if you will do it \nsomething like yourself with different web services, you need to remember that we have all possible ways to transfer \ndata that is commonly used in the REST API. You can use address parameters, query values, header values. \nRemember like we did in our post query special headers setting. So it's like technical settings that will be passed as \npart of our query. So creation is also capable to provide headers and even cookies could be provided separately.  \n  \n  \nSpeaker 1\n \n So if you do some operations with third party system which requires some authentication or requires some cookie \nfor like your user settings, then it's also possible to use it in your query. So it's very universal tool. In my case I do not \nneed request parameters in this example but I need response parameters. So let's save it again just not to lose \nanything. I will use response parameters first automatically. Let me show you. First of all I can run send test request, \nno parameters, no authentication so I just go and send it and I have a responsive JSON or in row HTTP . Of course \nJSON looks much more friendly for me and I will just copy this data and this is just an example of what web service \nanswered me. Okay, this is my response then I go to the method switch to response parameter.  \n  \n  \nSpeaker 1\n \n So my idea is to tell creatio how should I parse result data in order to extract specific values from it. So in my case \nresponse parameters can be added manually or we can use special very effective tool which is called quick setup \nand I will use example of my response body and give it to system in order to detect what are the possibilities, what \nare the possible values that we can get out from this example. So I will use setting of response parameters with the \nhelp of example in JSON quick setup example of response in JSON of course I have to paste my example of JSON \ndata obtained as a result from my test request. Then I click next System was capable to parse my data.  \n  \n  \nSpeaker 1\n \n As you can see it was it detected that I have two collections one is called cash sell it list of sell prices so bank sells \ngold bars and cash byte it looks like they have this data. But zeros tell us that possibly they are not really planning to \nbuy anything. And it's just like useless part of the data for us. So we can select what part of data is interesting and \nwhat part can be skipped because in our case we do not need it. And this is a very good example because in my \ncase I do not need cash buy part, but I need cash sell. Okay? And we can select only part that is necessary. It's \nimportant.  \n  \n  \nSpeaker 1\n \n This is very important because in real life examples, for example, you can call some foreign currency exchange rate \nservice and you know, we have almost 200 of different world currencies and you may face maybe 4 or 5 or even \n1000 of records, 4 or 500 or thousands of records with different values and parameters as response. So it will be \nreally important for you to select only parameters that you really need to get from results of web service. Because \nsometimes web service result body is quite excessive, including a lot of information that you don't plan to use or just \nnot useful for you. In my case, I am interested in cache cell list and I will save it. Okay? So this helped me to avoid \nmanual registering of parameters. It's possible I can create such parameters manually. I can reproduce everything by \n\n--- Page 11 ---\n\nmy hand.  \n  \n  \nSpeaker 1\n \n But using this quick setup tool by examples is much more efficient. So I have a root item here which represents a \ncollection is array. And also it's interesting to mention that creature uses such thing called JSON path. JSON path is \na kind of address of a value inside of a JSON body. So this value helps to detect and get corresponding value out \nfrom JSON body text and creatio is using it to allocate and find the corresponding parameters. As you can see, it's \nbody parameter and inside of this array we have pairs of data weight and rate. Let's look at our data closely. Weight \nusually so it's shown as a text, but physically it looks like a integer number minimum is 1 gram and maximum is \n12,000 grams, which means 12 kilos. So we can afford to treat weight not as text but as integer.  \n  \n  \nSpeaker 1\n \n Because we see that for all data values here it will be nice if we have an integer so we can treat results as integer \nand system will be okay with it. But when we go to rate and see some examples sometimes. So in general rate is a \ntext and sometimes we see thousand separators and sometimes you see it even twice. So it turned out that this \nmechanism which gets data automatically with the help of data service works poorly with type conversion. That's \nwhy it makes sense to keep rate obtained as text. And if you really need to work with it, as with decimal, obviously \nthis is a price, so it should be decimal.  \n  \n  \nSpeaker 1\n \n So if you really need so you can parse this data lately after you've got it from the web service and then later and then \nyou can save it as you wish. In my case I keep it simple. I try to not spend too much time on such data type transfer. \nSo I prefer to keep it as text. So it will be just a good for our demo. It will be not so suitable for real life calculations. \nBut later it will be not a problem for you to use date type conversion using. For example, you can use script task for \nit. If really interested we can try to do this. But I'm trying to, let's say save our time and to not to go quite far from our \ndata obtaining from web service.  \n  \n  \nSpeaker 1\n \n Okay, so this example takes result data and parses it and finally will present our data as collection of data records. \nWe can save it. Save it. And this information is now saved in our configuration section. Now I propose to make a five \nminutes break. I promise not to go too far and then we will continue. So let's move on. And we finished on the \ncreating of our web service. Checking out that our web service was saved into our package. This is very important. \nAnd now we will use it. So what how we can use it? We can create a business process which will run this call web \nservice item. We will get response data. But we need to think of where we plan to save set of records with weight \nand rate information. We have only two possible options. One is memory.  \n  \n  \nSpeaker 1\n \n But it will require some C sharp scripting for us in order to keep data in redis memory. For example, I prefer to make \nit more simplified and no code. So we will save our data into our database in just a simple lookup. This lookup \nrequires integer weight and text rate. We can easily create it ourselves in this package. So I will do it Add object. This \nis necessary to organize storage of our data. And this storage will be named USR gold price. No, we can do it parent \nobject but not base lookup because we don't need name and description. I will use base entity because it will only \ngive us standard parent columns and we can add business columns ourselves. So we will create integer usr weight \ncolon. It will be integer and one more will be text 50.  \n  \n  \nSpeaker 1\n \n\n--- Page 12 ---\n\n The minimum one usr rate will be our rate column text 50. You may ask me why text? The answer is because I do \ndemo of getting data in real life. We will need to save our text values first or maybe to use them and process before \nsaving with the script task and then we will use a decimal value to save finally converted value and in my case I went \njust to keep it as demo for you. So we'll save a text rate data as we get it from web service and that's all. No anything \nelse we can publish our object. As you remember publish always performs save first so we don't need to click save \nbutton. Save was performed and publish was done. Great, now we have this object already applied.  \n  \n  \nSpeaker 1\n \n One more small step we can go to lookups and register this object as lookup. So we click lookups new lookup find \nour gold prices save it. So now we have this lookup we can open its contents but we have nothing there. We can \nopen properties and create data binding item and save it into our package. This is necessary to remember \nregistering of the object as lookup. This is mandatory step if you want to go to your lookups and find it when we will \ngo when we will deliver our solution to test environment. So now my gold prices object is ready and we can move on \nto work with processes. So we registered our web service and we can use no code solution with processes to get \nthis data from third party.  \n  \n  \nSpeaker 1\n \n We can create new process name it like USR yet road price main process this is main process because I also plan to \nuse sub process to parse my collection. That's why I call this processes main process. No initial arguments simply \nstarting our process by manual start and the first step we need to do is call web service process item and which web \nservice to call. We have our ID banking web service then which method to call? We have the only one method that's \nwhy system selected eight method for us automatically. We don't have any request parameters. When we switch to \nadvanced mode we can see response parameters and response is our collection with couple of values here also we \nwill get HTTP status code which will be useful to check different errors and analyze what's actually happening.  \n  \n  \nSpeaker 1\n \n And sometimes full response body will be important because it will be it will include everything obtained from third \nparty without any parsing Boolean success property and probably that's enough. And we also have a SO request \nbody but it looks like this is an input parameter and only for very specific cases. So I don't know how to make a no \ncode example with this response request body so we will not use it now. Okay, so when we run this call web service \nwe can run it like get Gold prices. This item will finally run this query. Let's go to primary mode, get code prices and \nit's important results will be saved somewhere inside of this item inside of the response parameter collection. So we \nwill obviously have to process this collection somehow.  \n  \n  \nSpeaker 1\n \n And first of all I will show you some error handling in case if our request finished successfully. We can turn this flow \ninto conditional flow by clicking on this change type button and then set conditional flow so we can name it okay \nand we can check condition. This condition will include just boolean success property. If it's true then we will go \nhere. Otherwise we will stop and we will have another terminate item code error and we can go from our call web \nservice to this terminate item. You can name it error means something is not good and we can just turn our flow as \ninto default flow. Default flow will be activated if no one from conditional flows worked for us and default flow will be \nour error handling.  \n  \n  \nSpeaker 1\n \n So if we not successfully code our web service, no need to try to perform next steps. We just need to stop our so \nabort our process and use a separate terminate item because it will be stored in our history of execution so we will \neasily understand that it finished with an error. Okay, but if everything works well, we need to think of the place where \nwe plan to keep our data when we first run it. Obviously our data table will be empty so no visible preparation \nnecessary. But when we run it next time our data will be not empty and maybe it makes sense to clean it with the \n\n--- Page 13 ---\n\ndelete data item. So I will do this delete data and this will be an item to remove data from go price object. And as \nyou can see we have kind of protection here.  \n  \n  \nSpeaker 1\n \n This protection means that for delete data we must use some parameter. If we don't, this will not allow us to save \nprocess and it will show us errors. So we must use some parameters here. And this is kind of protection from \nunintentional delete of all the data. But in our case we intentionally want to do this. So we have to perform some \nkind of fake query which will be always true. And that's how we can make this correct condition to delete data. So I \nwill make a filter like ID is filled in for any existing record. This condition will be true and that's why I can use it. And \nit's quite easy and simple. It will not require too much resources from system to make it. So this will be an item like \nclear prices storage.  \n  \n  \nSpeaker 1\n \n So we delete prices from our storage and then we can use so we have a Collection and we have two options. To use \nno code approach with sub process to parse collection or to use C Sharp code in order to parse our collection with \nprogramming. Of course I prefer no code approach. Let's save temporary our current progress. Oh, it tells that the \nchange is saved. Cyclic change in packet hierarchy. Probably it's because of I forgot to make dependencies and \nsettings. Yes, it was my fault. Okay, it was unusual, but it was my fault. Well, it's because of current package system \nsetting was pointing to classic UI package. I have to switch to realty. Yes, modify my setting and save again. Now I \nhave no cyclic dependencies. Let's go and check our packages.  \n  \n  \nSpeaker 1\n \n So realty package should be dependent from dev classic and dev classic package should not be dependent from \nrealty. Yes, looks good. Yes, looks good. Very good. So now no cyclic dependencies, no troubles. And this was just \nbecause of the package. So that's why. So we worked with process library. If you select a corresponding package, if \nyou start to create your process from here, then your process will be okay with the correct package setting. So \npossibly we have one more plus for creating processes from configuration section, but not from the process library. \nOkay, we have first now let's do not repeat this mistake again and we will select our package. Add one more \npackage. I need a sub process to parse my collection. The main idea how we can parse collection is to make a sub \nprocess and to use arguments as parameters.  \n  \n  \nSpeaker 1\n \n So we'll use parameters and I was a process to accept collection data values and I will make my process name USR \nadd gold price subprocess. So it will be my sub process to add the gold prices. I need parameters because the only \nway to transfer data from main process to sub process is sub process parameters. One parameter will be integer. So \nI add the parameter which will mean weight integer input which make it makes it read only inside of my process. But \nI don't plan to change it. So I only plan to get it as input value no initial values. Save it. Another parameter is text 50 \nthe shortest one and it will be rate and it's also input and no initial value. So here we have a couple of values we \nexpect to get at the beginning of the process.  \n  \n  \nSpeaker 1\n \n Then we will use our process and our process structure will be really simple. We will just use one add data item. We \nwill add data into gold price object add price and we will fill one record and only couple of values weight and rate will \nbe filled in very easy rate and weight. So rate will take its value from corresponding Rate text parameter weight \nClicking on this lightning button, we'll get its value from corresponding integer weight parameter. Please note select \nparameter window always filters available parameters according to the data type. So that's why we see only \ndecimals and previously we saw only text parameters. Okay, we have this stuff. So you see the sub process is pretty \nsimple and we can save it, close it, go back to main process.  \n \n\n--- Page 14 ---\n\n \n  \nSpeaker 1\n \n Now we will use an item called sub process and I will use this orange item and place it into my diagram. Normally \nwhen you want to run a single instance of a sub process, you just specify your sub process name and single \ninstance call means you have to transport. They are just pair of values and this means that you will run your sub \nprocess only once. But in our case we plan to work with it and parse collection with the help of sub processes. So I \nwill use special settings. Now please be careful and watch here what I will do now. For example, let's go with wait \nfirst. So we plan to turn this sub process into a collection processing mode. And this can be done by selecting \nspecial values here. And such values should be taken from collection.  \n  \n  \nSpeaker 1\n \n So I click on this lightning button, select process parameter and then I will select process elements and our get gold \nprices call web service. It returns collection and we have corresponding weight column in this correction. So I have \nto double click it. And that's how our sub process immediately turned into collection processing mode. And it will run \nas many sub process instances as many collection data records we have. And we have execution mode sequential \nor parallel. In my case, no need to run parallel sequential means one by one and we have input collection. We already \nspecified weight column for it. Now we will set rate column from process parameter rate double click. That's how we \ndo this. Run it in the background is not necessary here will probably only take some additional performance.  \n  \n  \nSpeaker 1\n \n But in here we can just run the process and we are interested that in finishing it fully synchronously. No strong \nreasons to run it in background creating some scheduler executed tasks. So we just can run it simply in a current \nthread. Okay, when it runs we can also call it like add prices. Okay, it prices and it will run ad vote price sub \nprocesses and we'll have as many sub processes as many collection records you found. So that's it. Our example is \nready. So it will be our happy finish item. This is our start. It makes sense to note and make names for all the items. \nIt will be like a documentation which makes it easy to understand and we have current version. Okay, let's Save it. So \nnow we have this process and we can start it from here or from process library.  \n  \n  \nSpeaker 1\n \n Let's reload it by clicking on this icon and we have to start main process. Let's start it. But also before starting it we \ncan enable trace to be important for our debugging and we can also. That's it. Okay. Trace is the only one option \nsuitable for us. So let's run this process. Then we go to process log. We will see our main process started and it took \na bit longer than 1.2 seconds. And then you see number of subordinate sub process instances executed quite fast. \nBut we have approximately 11 items here. So we can check main process and open its execution diagram so we can \nsee how many times our sub process started. 11 starts, no errors and it looks like everything went fully okay. You \ncan also see trace data. We are interested in how exactly our gold prices were obtained.  \n  \n  \nSpeaker 1\n \n So we can click on show trace data. You will see all the parameters in your collection. We can see technical \nparameters like response status, code 200 means everything is okay, full response body sometimes can be \nimportant. And it looks like in our example everything went smoothly without any errors. So this trace takes some \nadditional performance. But in general it's a good idea. And this trace helps you to understand if something goes \nwrong. And you will see exact parameter values, exact status code. So I recommend you to keep trace on if you want \nto support possibility of quick discovery of something if something goes wrong in your integration. So in my case \neverything went well and we go to lookups to see exact prices. So code, prices section, lookup list and we can just \ndisplay weight and then we can display rate, save it.  \n   \nSpeaker 1\n\n--- Page 15 ---\n\n  \n Also it makes sense to look at the columns of creation, date of creation. Okay, and now you see we have all obtained \ndata saved in creation. Physically this is text. So if really needed we can use parsing. We can use some C sharp \nscripting to parse such values into decimal and then save them into corresponding decimal fields. But technical side \nof running queries and asking third party system and to return some data. I think it's quite clear in case if you have \nany questions, feel free to ask, I will be happy to answer. This is example how we can call third party apps. And at \nthe beginning of course you will need some example of a call some URL, example of parameters, maybe some \ndescription and documentation how to call this password public API. And you have all steps made with no code.  \n  \n  \nSpeaker 1\n \n And finally we have a process which takes probably less than hour to develop with all the explanations and we \nsuccessfully got our data. If we start this process one more time, you will see in our lookups, you will see new data. \nSo you see date in time was changed. So our contents of previously obtained records was successfully removed and \nwe have new data records inserted just seconds ago. This is also important when you develop your integration to \ncheck how it runs multiple times, because if it runs once, it's okay, but you should expect it to run regularly and it \nshould properly include the existing data and correctly operate with it. Probably removing it, probably updating it. It's \nup to you in case, if you have any questions about it, tell me please.  \n  \n  \nSpeaker 1\n \n My next topic for today is to explain you how to use Clio tool and explain why you need it. So first of all I should \nexplain why we have some additional tools and not inside of the base platform. So previously we already had a tool \nthat was necessary to support developers and this tool was called Let me show you Delivery Tools and Workspace \nConsole Overview. So previously we had a special tool called Workspace Console and it's probably more than 12 \nyears old and it was used only for developers and only for developer tasks. Sometimes tasks were included based \nproduct preparation, processing resources, translations and so on. And finally it evolved into a complex tool with \nMany more than 50 different functions related to C Sharp sources, related to stored localization files, XMLs working \nwith file system, working with version control.  \n  \n  \nSpeaker 1\n \n And so it has a lot of different, let's say quite technical purpose, which probably will be not necessary for end users. \nSo developers used it for a long time. But now this is an old tool which has its own disadvantages and developers \nwanted to make something new, so they made a new tool called Clio. You can find it in GitHub, ATF Clio. If you \nsearch for this, you will easily find GitHub repository. You can find its root folder and then you can see a list of \nowners or maybe authors or contributors into this tool. And you need to remember that most of them are Creature \nemployees, only some of them are outside of a company. So you see some strange users here and there are some \npeople from outside of Creation, but most of them are from Creature.  \n  \n  \nSpeaker 1\n \n So generally you can consider as this tool was written by Creation in general, but this tool has open source code. You \ncan easily not easily, but you can analyze its source code. You can like propose your own improvements into it. You \ncan even add your own functions and also collaborate and helps to fix maybe some bugs and maybe to improve \ndocumentation and so on. So this tool is open sourced, so it's free of charge and you can use it at your own. This \ntool has also more than 50 different columns comments and I need to quickly show you how you can use it and why \nyou may need it. I will focus on the most useful examples that you may face when you develop your projects.  \n  \n  \nSpeaker 1\n \n But you should keep in mind that this tool was written by developers of base product, so they had their own reasons \n\n--- Page 16 ---\n\nand needs to operate inside of base product. And now you will see this difference. So let's go and I will show you \nhow to use it. This tool was designed to use by command line, so you should use some Windows or if you use other \nthis other operating system you should use command line for it. And first of all we need to check presence of this \ntool and you can find documentation here how to install it. So let's let me show you. You must install dotnet core \nframework on your PC if you want to use Clio.  \n  \n  \nSpeaker 1\n \n I already have it dotnet tool list G this is command showing me existing installed dotnet core tools on my PC and \nClio is already installed here. Okay, I can remove it dotnet to uninstall Clio G It means remove it from my system. \nNow if we check we have no creature Clio tool on my PC. This is a common line utility. It's managed by command \nline parameters and the most important property of it. It operates with target creation system with the help of web \nservice calls. So Clio is managing creation by help of web services. It means that it can manage local or remote \ninstance the same well so unlikely to workspace console which required file system access and database access to \nyour creation. Clio requires only Internet network access to your creation.  \n  \n  \nSpeaker 1\n \n Okay, let's install it.net sorry to install Clio G this is command that you can type in your windows command terminal. \nThis is two this is common to install Clio. It will install the latest version. Let's see what version we will have. Now of \ncourse this comment requires Internet connection so it goes to nuget searches for the last package which it can \nfind. And now you see the Last version is 61016. So this is current latest version of Clio. Okay, we installed Clio but \nnot set it up fully. We already can run Clio command to see plenty. Oh sorry, my fault. Plenty of functions that it can \ndo for you. So let me show you where is my scroll bar Here you see more than 60 different functions and I have.  \n  \n  \nSpeaker 1\n \n I have suspect that the most early created functions are at the top of this list and the most recently lately created \nfunctions are at the end of this list, you will not need all of them. So it's like a universal tool. It has a lot of different \nparameters, a lot of different comments. So I will show you the most important, the most practical that you may \nneed. And after installation we need to tell Clio what environments we will work with. Because Clio operates with \ntarget website and it needs to know URL, login and password. So we can use command clio show webep list and it \nwill show a list of registered applications that are already present on my disk and physically saved into this app \nsettings JSON file located somewhere in my user folder on disk. You see my previous attempts here.  \n  \n  \nSpeaker 1\n \n So I already have some previous environments registered. I have to register my current environment. Clio reg web \napp I need to show you reg web app. Of course you need to know how to spell certain comments, how to get their \nparameters. So you can try to do something like this. And for some comments. Oh, doesn't show us. Okay, let's do \nthis like this. So for most of comments you can type minus question and you will see some error that it did not \nobtained, did not understand the command. And it will show you a list of all supported comments. Most of \ncommands have their short version and most of parameters have their short version. So in order to save your space \nyou can use shorter parameters. And the reg the app command is used to register your app.  \n  \n  \nSpeaker 1\n \n So it will be included into this file and then you will refer to it by name. This is easier than providing URL, login and \npassword each time when you need to operate with target environment. So let me register my current environment. \nClear reg the web app. I already have some example, so let me type it. So I have D1 to do. Yes, this is my \nenvironment. Okay. L means login supervisor, P means password supervisor and my name will be D1. So this is how \nI do my register. Copy it for you so you will remember it and you will understand why I need it. So when I register my \napp. Oh, we have some additional troubles. And path environment list is net core. So we have some troubles in \nexisting app settings. JSON okay, it was not expected. Okay, show the list.  \n\n--- Page 17 ---\n\n  \n  \nSpeaker 1\n \n Wow, we have some troubles in this file line 41. Probably because I have some older versions of such settings. Okay, \nlet's go where it tells users. What else? Users or user app data Local creation My user app data local creature. Sorry, \nsorry. Local creation Clear App settings JSON possibly I have some incorrect settings here or maybe outdated \nsettings. Oh, I have something like this, which obviously it doesn't look good and probably it's a result of some \nprevious stuff. It looks like I have some incorrect settings here. So okay, environments closed. Then here it's end of \nenvironments. Here is end of all stuff. Also I could remove my previous items here. So I have no environments. Now \nlet's try to ask it. Clear show web app list. No troubles. You see, everything is okay. Clear reg web app. Configure it \ncorrectly. Okay, great.  \n  \n  \nSpeaker 1\n \n So now we can do some simple operations with it. Cleoping and then we have different options. But the easiest way \nis to use E key for environment and then environment name. So this cleo ping will physically check availability of our \nweb service. And if it's okay, you will see yellow. Sorry, not yellow green color text. So ping was successful. One of \nthe functions that can be useful is restart. So you can use restart function. Restart comment clear restart ed1 this is \nfor restart of our app. You remember we used maintenance tools add on for this. But also you can use this \ncommand to perform restart. Usually it's safe and quite quick. You will see what is happening. Now our application \nis being restarted. It takes up to 10 seconds and sometimes you will need this restart as part of your development \nprocess.  \n  \n  \nSpeaker 1\n \n You remember when we modified some objects, added new columns, we had to restart our app to properly apply \nsuch changes. So we had such scenarios in our training when we needed it. And simple log out and login did not \nhelp. Okay, so let's move on. We already started restart. We have a lot of other commands and you will see plenty of \nthem. A lot of comments. I will show you the most important ones. So from project development point of view, you \nneed to know that Clio can really help you with saving packages and loading packages. So you can use Clio to \ndownload packages. This one, this comment. Download packages from source environment. For example it can be \ndeveloper environment and then you can use install package. Let me find it. So we have download and we should \nhave upload. Push pkg.  \n  \n  \nSpeaker 1\n \n Let me switch find it should be somewhere here. Yeah. Push pkg. It has also short command install. I don't know \nwhy developers did not show it here. Install command is capable so it should be shown here. So you see \ndocumentation probably is not perfect. And the install command loads our package to target environment. This can \nhelp us to organize CI cd continuous integration and continuous delivery with a single script that can be started with \nthe one step one operation. We can download and then we can install it. But also you need to know that create Clio \nhas more other columns. Sorry comments and some comments like we use for download or install are using \nstandard base product creation Web services. So system that we work with doesn't require any special setting.  \n  \n  \nSpeaker 1\n \n But if you want to use all power of existing Clio commands, you must perform special command and this command \nis named Install gate. This Command downloads from NuGet and installs in your target system special package \nwhich keeps DLL inside. And this DLL includes all necessary web services that enable this set of commands. So \nsuch web services, simply speaking, are parts of Clio to implement corresponding comments without this comment, \nwithout install gate, without additional package installed to your system, CLIO will be not capable to perform \ncorresponding commands. It will show you error 404, which means missing functionality in your target environment. \nSo Clio only runs web services at your creature. And if it fails to run web service that it needs to perform a \ncorresponding command, you will see this error. So let's try.  \n\n--- Page 18 ---\n\n  \n  \nSpeaker 1\n \n Let's try to run a command to install gate Clio install gate ED1 this is required in case if you want to enable full power \nof Clio commands. So in my case, I will do it in my source environment. This takes time because it Downloads \npackage from NuGet, it installs this package into your target environment. This package is called Clio Gate. So you \nwill see new package Clio gate in your system. And this package will have so called file contents and file contents \nwill include compiled classes for your web services necessary for Clio to work. Let me show you. So here we have \nconfiguration section. Okay, it looks like we have some stuff here. Let's reload the package. Reload configuration \nsection. We have some interesting information here. I did not expect it. It looks like we have some troubles with all \ndata for compilation.  \n  \n  \nSpeaker 1\n \n So system tried to compile and failed exceeded narrow try count work process. So our IIS prevented our system to \ncompile. Let me check. Did I detach? Of course, my visual studio was detached. Okay, I need to look at such \nquestions. And also we see some troubles with old data and probably it's file system issue. Okay, so now system \ntried to install and compile package named Clio Gate. I should expect it to see it here. No, now sort was performed \nwith this case insensitive sort. Clio gate is a package with functions that are necessary to run Clio commands. And \nyou see only a couple of data items here. Of course, it's not full stuff. So we go to file system, we go to our \napplication, go to our packages Clio Gate package.  \n  \n  \nSpeaker 1\n \n You can see its size 5 megabyte of executables not so little files Bin and here, here and here are DLLs included as \nfile content for this Clio Gate package. So such DLLs are used to execute Clio commands. They implement the \nimplement web services, install such classes into creature server side. So that's actually how Clio may work on a \ncertain environment and how Clio may create and implement new comments. Because if you want to run something, \nyour target system must be able to do this. Okay. So if necessary we can fight with it. It looks like I have not so much \ntime today to fix this configuration issue. My command to install Clio gate package was quite correct. So it looks like \neverything is okay. So now I can show you some examples how you can use Clio efficiently for project development.  \n  \n  \nSpeaker 1\n \n And this will be comments to save and load environment settings and Sorry, Save and load packages. Let me show \nyou. I already have another test environment. You probably forgot about it. So we have D1 Studio as development \nenvironment and D2 second was used as a target and the test environment. Let's check it out. It should be alive. So \nlet's go D2 it's used as test environment. So why it's loaded? I can also use Clio to. Sorry to register a new \nenvironment. So we load it here and then we will use it. So clear rag web app. I need to register D2 and I will call it D2 \ntest to make it clear that it will be my test environment. Okay, register it Clio show the back list. Okay, my D2 test and \nClio ping P D2 test. So.  \n  \n  \nSpeaker 1\n \n So I will check availability of my second environment and it looks like should be okay. Yes, looks like Bing is okay. \nHere is my second environment. So my plan is to show you the most useful usage of Clio for project development. \nThis is CI CD automation for saving and loading of packages. I already have examples of scripts that perform this \nsave and load. So let's take this one. Probably Clio download so we can download set of packages. Let's check out \nhow many source packages we have. So we have Dev Classic. Okay, here Dev Classic. Then we have USR Realty and \nalso we have USR Realty migration. So we have three packages here. USR realty migration and Source environment \nis dynamic one. So Clio download is the same as Clio pool PKG command and we can download set of packages.  \n   \nSpeaker 1\n\n--- Page 19 ---\n\n  \n Not only one but several packages from source environment. Destination path is somewhere like this guided dev. \nOkay, let it be May 2024. So we will finally have a result of a zip file including all our packages. We can use this zip \nfile into next command which will be used for loading clio install the same as clio pool push pkg we will use source \nfile I will use on target environment D2 test and we need to use logs because it's important to see some technical \ndetails. So I will share such comments for save and load with you. It will be really important for you if you want to \npractice with it. And now let's check out how it works. We will remove unnecessary examples and this will be my \nsave and load example of CI cd.  \n  \n  \nSpeaker 1\n \n Let's try first system will save three packages into gz files organized into one single zip file and then it will be done \nand as you can see it makes it as a one operation if you do save manually saving of an app or saving of a separate \npackage. So you will have to perform it with separate structure steps. As you can see it went but not so fully \ncorrectly. I will remove unnecessary files from my example the 7th of April so those are here. So here is our saved \nzip file. So it looks like save part went okay and may part it looks like I had couple of exceptions here. Let's analyze \nour logs.  \n  \n  \nSpeaker 1\n \n So you see we have location packages more file descriptor more than one file app descriptor JSON what it is what \npackage it's about real to migration No, I don't know. So something wrong with application descriptors we can check \nit at our file system. Probably it's a result of something messing with package dependencies. So our realty has its \nown information of app descriptor yes, this is realty app. Okay, realty migration has its own app descriptor yes and \nour dev classic should have no dependencies from existing reality stuff and it should have oh we have app \ndescriptor extension.  \n  \n  \nSpeaker 1\n \n Something is strange here and it looks like probably system failed to work with it but it looks like it's not a big trouble \nand you see one more issue here parent schema and was not found yes, this is more serious trouble because it \nlooks like our target environment was not fully prepared to install our changes because it miss customer 360 app \npossibly previous error message that we had here previous message with this stuff here probably it was also \nmissing corresponding app and we used so our solution expects that target system will help customer360 in my \nexample customers current our target environment did not have customer 360 that's why we have this stuff. So in \norder to fix it of course we have to install customer360 first and then our solution next. In this case it will be loaded \nfully correctly.  \n  \n  \nSpeaker 1\n \n But now we can test our target environment. So usually we need to reload it. We can find our items like oh, we don't \nhave any, probably did not like it. Okay, we have to install customer360 here and then load our solution. So you see \nonly Dev Classic was loaded here and recent stuff was not loaded. Okay, let's try to install customer360 install. \nContinue. I did not enable file system development mode here because it's like a test environment and no any \ncreation, no any external ID. So let's install it. I install customer360, then I can try to load my settings again. That's \nhow we will see our working example. So I plan to show you fully correct transition of my environments. This is \ncustomer360 installation on my target system. As you can see previous results of manual load of package.  \n  \n  \nSpeaker 1\n \n Manual load can be done with new application and then install from file. Now we have successful installation. Great. \nIf we reload we will see customer360 app added. Yes, customer360 was added. Now we can try to install our stuff \n\n--- Page 20 ---\n\none more time here. Let's remove previous package. So we will. And one more thing before we continue. So this is \nnot so obvious, but when we developed C sources we used external editors. We have C code saved on disk only. And \nin order to make everything correct, we need to download all items that we develop manually inside of our \nembedded editors back to disk. And then we have to upload changes from disk. This is very important because our \ndatabase part of C Sharp sources may have old C source.  \n  \n  \nSpeaker 1\n \n And if we ever try to compile our package on target environment, we may have very unpleasant situation when we \nwill try to compile old contents of C sources instead of actual one. So in order to make correct export of your \nsolution to test in production, we need to save everything on disk. Then we have to take everything from disk update \npackages from file system. Now you will see system will show us differences in C Sharp code. Because both \nexamples were written here and here were written with the help of external editors. This is very important. Now our \nsystem is ready to export. So let's do this again. Save and load. Thank you Adrian for your time. Yes, we are almost \nover. We will continue tomorrow with preparation for developer action and also answering your questions.  \n  \n  \nSpeaker 1\n \n It will be not so hard and thank you for your time. So now I just plan to make it correctly with save and load and then \nif everything goes well, we will see our Apps we will see our functionality loaded to our target environment if \nsomething goes not as planned. This is also good because we will see some exceptions. You will see how we can \ntroubleshoot them. It's important to understand how you may do some fixes when your package is not installed as \nyou plan. Now you can see. Oh, do we have any errors? Yes, we had some errors here and it's interesting because it \nshould not be so we should not have any issues here. Possibly it's about data. Let me check here we have a log file \nand we have data insert issue.  \n  \n  \nSpeaker 1\n \n So sys module entity USR realty no then this module in workplace studio so violation of primary key. Oh, it's because \nof data binding which does not keep correct IDs but duplicate cases module in workplace. So it's registering of a \nsection in the workplace and this duplicate is possible because of the way how data binding saves it. So we have \none data item failed to load but in general okay, one more data item failed to load so we have only troubles in couple \nof data items. But general data was loaded so we have as a result some errors. But this is because of something is \nnot exactly the same as our original stuff. Okay, let's try to reload our section. Let's see do we have anything loaded \nStudio my applications we have realty section.  \n  \n  \nSpeaker 1\n \n We have classic we miss reality sections here because such data items were not loaded. I will show you how you \ncan fix it. Let's go to advanced settings. Let's find our new packages loaded here so we can search for realty \npackage and we can see couple of data items. So let's see only status has error or needs to actualize here so you \ncan see list of items that were failed to install Couple of SQL scripts from base product we don't care and only one \nitem in our reality package was not loaded. We can see error message text and properties. So violation of primary \nkey. It looks like system can't find the correct value of what and it's hard to see. Okay, let's see. So it can't find correct \nduplicate value of sys module in Workplace.  \n  \n  \nSpeaker 1\n \n It looks like we already have sys module in workplace ID and it looks like this data entity was not good. So we have \nsome items here and we have key which was not ID and key was used by section and workplace. So we can fix this \nit's not good and this is behavior made by data binding tool. I don't really like it. So we can fix it with the another data \nItem organizing key by ID that will prevent the data from inserting twice with the same id so we can fix it. Let me \nshow you. Since module in Workplace in Studio so it's our reality section. This is a data item. This module in \nworkplace for Studio and such settings for key is not good ID key is better position for update if in case if record was \n\n--- Page 21 ---\n\nfound.  \n  \n  \nSpeaker 1\n \n Great, and we can save it. And we have a lot of warnings, but it's about existing date. So let's actualize it save it. Just \na lot of warnings about reorganizing of the same existing set sections that are already present in data. And also one \nmore thing which we potentially have the same trouble sys module and workplace for this realty and it's 26 my \napplication. Also it makes sense to our ID is already set here. Okay, great. Probably you can put position updates \nchoice data save it. Great, Everything is okay. So we fixed it. We have to save everything on file system just to make \nsure we will correctly have all the data well in our repository version control. So now you will see that it's possible to \nsave and load packages again. We can prepare something like order like v1 plus old file.  \n  \n  \nSpeaker 1\n \n Now we will have a bit better version of it. Okay, saved. Now let's try to run this transport again so it will be final one. \nAnd this is example how you can automate delivery of your changes. How you can take data from developer \nenvironment and automatically save and devote it to some other task target test environment. Of course, as \ndeveloper you understand that sometimes things are not going very smoothly. Sometimes we have unexpected \nerrors. And having such errors during the training is also good because it helps us to see how you can troubleshoot, \nhow you should search for error details and how you should do all changes. So now you see next time we load it \ntook significantly less time because loader is smart.  \n  \n  \nSpeaker 1\n \n Loader text takes zip file, takes information about its items, all the packages, all the items of configuration and it \nanalyzes date of modification. If date of modification of the loaded item is the same as date of modification of items \nthat you have already in your target environment, then it just skips it. And that's why if you have a big solution, but \nyou have tiny small changes, they are from recent upload that you did previously. It will only analyze changed items \nwhen loaded on target environment and final total installation time will be small. And now you see only couple of \ndata items that were failed were now updated and fully applied and everything else was correct. So now our system \nin our target environment has no errors. As a result of installation we can go to all packages to see items.  \n  \n  \nSpeaker 1\n \n Actually only base product stuff. Okay, don't care, no errors. Okay, so our package with realty was fully correctly \nvoided. All the items that we have were loaded well. And we can test it at our user interface. So you can go to \ncorresponding sections, you can try to create data records. You see all three actions, all three sections here. So our \nreality with columns you can create new data. So find me cat here. And you see now we have default values working. \nWe have some test data. Test price, negative price, validation works too big price will also work and system will not \nallow us to save because of server side. Okay, like this. But now you see price is more than 1 billion. So everything is \nworking as expected.  \n  \n  \nSpeaker 1\n \n So that's how you can deliver your solution to test and check it out and perform corresponding full scale test for your \nsystem to check how it works. Now you see details were filled in. So everything works quite well. And that's how you \ncan do some automation with Clio. Clio has also a lot of interest in other comments I will show you just one of them. \nClio SQL select name for contact. Okay, something like this. So this is example for Clio SQL execution. Sometimes \nwhen you work in cloud with cloud environments you just can't connect to the database directly and operate with it. \nSo sometimes you need to run some simple select queries in database to make sure you have specific data. And \nthat's how you can do it with your Clio.  \n   \nSpeaker 1\n\n--- Page 22 ---\n\n  \n So this is example of how you can read list of contacts from your database. Of course your queries could be much \nmore complicated. And when you run SQL queries please be extremely careful because SQL statements is the way \nhow you can easily damage your system, how it can easily destroy your database. So you should be extremely \ncareful and please check your queries before execution. SQL can really help you and to see some data directly. \nUnfortunately Creature has no tools to work with SQL easily from user interface. Now previously we had such tool \nbut was designed by some Russian partner. And as you remember, as you know, Croatia gave up any work with \nRussia or Belarusian partners and customers. So we also removed all of the add ons from the marketplace.  \n  \n  \nSpeaker 1\n \n And that's why now we don't have any fancy good looking tool to run SQL query from application user interface. But \nnow this is something that you can do. And the last information that you need to know about Clio is that it's also \npossible to use add on for Visual Studio named Clio Explorer. So Clio Explorer Is an add on that you can use in Visual \nStudio code. It automatically loads your information from file with connections for existing solutions. And you can \nuse a lot of Clio commands from user interface including SQL. So you can do something like this. Then you can run \nyour query. Let me see where there is a button to run query. This one. So this is Clio SQL comment and it tries to run \nmy query. But what? Oh, D1. I already connected. Probably I connected. Yes. What's wrong there?  \n  \n  \nSpeaker 1\n \n Split editor. More actions. Oh, probably this. Yes, it was case sensitive. I don't know why it's case sensitive. But now \nyou see some data we got from the database and you have some kind of UI stuff. But with the help of Clio Explorer. \nClio Explorer uses installed Clio Explore tool. So without Clio installed it will not work. But this is user interface \nfeature which can help you to work with a particular environments. Would you like to current. No, no, no, no. Thanks. \nSo we have a lot of functions of Clio the most commonly used and some of them. And also you can use Clio \ncommands from terminal window of Visual Studio the same as we used in other Windows console bars. So, thank \nyou for your time today. Today our session is over. We will prepare for the exam tomorrow.  \n  \n  \nSpeaker 1\n \n As usual you will receive video recording of today's session. If you have any questions, ask today or prepare \nquestions for tomorrow. Because we will have more time tomorrow. Thank you very much for those who stayed for \nthis moment. You will see videos soon. Thank you and goodbye. Hi Dimitri, it's boss here. Yes boss. Please. \nTomorrow I'm. I have other obligations to attend to, so I will probably follow it by video. But is there any special \naction I have to take the fast track on development certification? Oh yeah, I will explain. So I will send you final email \nwith all video recording with homework for your fast track certification and quick explanations of what you should \ndo.  \n  \n  \nSpeaker 1\n \n So if you agree to run Fast track certification, you should just respond to my email and we will arrange individual \ndate and time for you to run your exam. Your exam will include check of the homework. So you should prepare \nhomework before exam starts. So you will have a couple of weeks to do this and you should prepare for the test \nusing self assessment tests at Academy. I will show and so at the exam we will look at your homework and you will \nrun your online exam test. Okay. If you fail, you can run this test again later. So don't worry. It's a bit nervous. I \nunderstand. And Fast track certification is free for our guided learning participants. Okay, cool. So you will receive all \nnecessary stuff and videos explaining how to prepare for the test, how you should answer questions, and so on.  \n  \n  \nSpeaker 1\n \n You will see the type of the homework Raki is asking will include. So let me quickly show. I planned to show it \n\n--- Page 23 ---\n\ntomorrow, but okay, if you ask now. So let's do this, I will quickly show you. So the type of the homework will include \nmaking your section, this one, making your detail, make programmed validation, some calculations, web service, and \nfor those who want to run an advanced level, some additional business process and adding data records and some \nautomatic update. You can use live Update to automatically refresh your screen. Or I will show you how you can use \nWebSocket messaging if you prefer. If you prefer to do it a bit more professionally. So the homework simply is just \nsimilar to what we did during our sessions. And it requires some programming for validation, calculations and web \nservice.  \n  \n  \nSpeaker 1\n \n So it requires some javascripting and C Sharp scripting. And so it will not take too much time for you, I think, and I \nhope that it will be clear. So we discussed all the steps how to do this. If you will have more questions, you may ask \ntomorrow. So Rakhi, I think that those who passed our sessions watched our videos and practiced with their own. \nYou can use even your own example because the name of the section is the same set of columns, very similar. So \nyou can use your training session environment to perform your homework on it. So it may be helpful. You do not \nneed to create a separate environment for your homework. Okay, thank you for your time today.  \n  \n  \nSpeaker 1\n \n Sorry for staying a bit later than usual and if you will have more questions, so prepare for tomorrow, we will have \ntime for this. Thank you very much for today's session and goodbye. You will receive homework assignment \ntomorrow as well as all video recordings and all the questions I will answer tomorrow. Thank you and goodbye.",
    "file_path": "creatio-academy-db/developer_course/pdfs/Creatio-Developer-12.pdf",
    "page_count": 23
  },
  "metadata": {
    "filename": "Creatio-Developer-12.pdf",
    "file_size": 258311,
    "created_date": "2025-01-23T16:27:28.165570",
    "page_count": 23
  },
  "chunks": [
    {
      "chunk_id": "04e56c79c017be59724ee5ddbd85d1d5",
      "document_id": "699402ad4f39",
      "content": "--- Page 1 ---",
      "chunk_type": "paragraph",
      "chunk_index": 0,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 4,
      "token_count": 5,
      "context": {
        "heading": null,
        "paragraph_count": 1,
        "position_in_document": 0
      }
    },
    {
      "chunk_id": "05d403a701e19aa50ee343f548777c70",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nToday is session number nine of our development on Creature platform guided learning. And today we will continue \nto study server side and we'll move on with integration tools. So yesterday we finished with our own web service. It \nwas made at creation site, was made with the help of C Sharp sources and we programmed it, we saved it in file \nsystem. We used Visual Studio to develop this web service. So we used our examples. Now you know, okay, now you \nknow how you can make your own integration tools. But in general, so integrations will require much more entities \nand will require much more tasks to exchange data. So it will be really hard for you to write a web service for each \ndata transfer that you need in your system.",
      "chunk_type": "paragraph",
      "chunk_index": 1,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 137,
      "token_count": 161,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 1
      }
    },
    {
      "chunk_id": "696092ff98cd373ba889abd306c344af",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo what we'll study today, how to use standard platform level tools to operate with data with the help of HTTP \nqueries. And we will discuss and I will show you examples of how to work with standard tools. And they are all data \nprotocol and data web service. Also I plan to show you how to call third party web services with the help of no code \ntools, with the help of settings for web services and call web service item. And at the end of the session I want to tell \nyou about Clio tool, Clio Commons. You will understand what is this, how it can be used, why you need some \nadditional tools. So we will discuss a bit more about system maintenance delivery and if you have any questions, I'll \nbe really happy to hear and to answer them.",
      "chunk_type": "paragraph",
      "chunk_index": 2,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 146,
      "token_count": 171,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 2
      }
    },
    {
      "chunk_id": "fbc714d11fb9e4dfb2cf522027d78868",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo don't be shy, ask any questions if you feel something that you need to know and let's move on. So integrations \nwith data tools. First of all I need to show you general integration capabilities that we have on board. Go to \ndevelopment guides integrations options and here you can see standard options that we have. We already studied \ncustom web service option and it offers us possibility to program anything we need to ask for data, to make \noperations with files, to use any libraries. But this approach obviously requires some programming at creation site. \nAnd also this approach requires programming at third party site in order to normally correctly call such service and \nto get response data parse such response. So I just want to say that in general it's quite expensive approach if you \nneed to do a lot of different operations.",
      "chunk_type": "paragraph",
      "chunk_index": 3,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 149,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 3
      }
    },
    {
      "chunk_id": "20bc138b3f213994511605173d2a4272",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAs you can see we have other options to integrate with creation. We have two options for data transfer such called \nCRUD operations which means create, read, update and delete. So standard simple operations that you may need to \nwork with your data and to organize. Possibility to read some data for third party app or to make some inserts, \nupdates or deletes in creation by commands from other applications. And we have two different options for this. \nOne is called Data Service, another is called Odata. And Odata is quite common because it was designed by \nMicrosoft and it's possible to find Odata clients as third party sources. There are a lot of tools that understand how \nto work without data. So developers of Creation decided to support this type of client. And data service is much \nmore unique.",
      "chunk_type": "paragraph",
      "chunk_index": 4,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 4
      }
    },
    {
      "chunk_id": "d9e424b8c76514dc6fde87618a7e48fc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIt's very specific to creature, but it offers you more options, more possibilities, more complicated calculations. And \nthat's why data services used for creation of client side and data service in general is more powerful than ODATA \nand more complex to program. So I will show you both ODATA and Data Service. You will see how it works. Also, it's \nworth it to mention that we have another integration option to run business processes. So you can use process \nengine service web service for starting or continue execution of business processes the same way how you can do \nit from creation client side. Physically, this web service is the only one to handle processes. And when we run \nprocesses from inner application. Let me remind you how we did it.\n\n--- Page 2 ---",
      "chunk_type": "paragraph",
      "chunk_index": 5,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 137,
      "token_count": 167,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 5
      }
    },
    {
      "chunk_id": "c9e0bdbf8fac217ab8913a1ae904b747",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe had the class on Freedom UI section, we can open its page and then we made an action to calculate average \nprice with the help of business process. You remember we did this calculation, we started process, now we have \nsome results, average price in dollars. Then we save it or close it. And that's how we finish our process. So physically \nwe did some calls to third part to process engine web service. Here you can see it. And the same calls with the same \nparameters can be done with third party applications. So it's possible to run processes from 30 third party. And of \ncourse in this case you need to pass authentication first. And we did it yesterday with the help of Postman tool. You \nremember we had the Postman authentication, we had set of authentication cookies. Okay.",
      "chunk_type": "paragraph",
      "chunk_index": 6,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 145,
      "token_count": 175,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 6
      }
    },
    {
      "chunk_id": "3af23300f86008a6e145daa4f2baa266",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if interested, you can just watch yesterday video and get more details. So today we'll focus on data transfer \nintegration options. And I would like to start from OData because it's easier, it's more friendly for beginners and it's \nquite easy to start from scratch. So what it is, this is a data transfer protocol which is supported at creation. We have \nall documentation about it. So for all data we have documentation explaining how to use it. And in general you need \nto know that creation supports OData 4 and OData 3. Unfortunately, OData 3 is not supported in packages. So it's \nnot supported for objects that are saved in packages compiled as Separate assembly. So it means that for your \nODATA integration, probably it's better to focus on OData 4 from the beginning.",
      "chunk_type": "paragraph",
      "chunk_index": 7,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 139,
      "token_count": 178,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 7
      }
    },
    {
      "chunk_id": "95a52942da6befe1872e69facd1deeb7",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe have a lot of documentation about it and if interesting you can find much more. And we have examples, we have \nreferences. So I prefer to show you something really useful. This article, it explains some general basics about how \nto use OData. We will try to make some examples and first you need to know that ODATA operates with the help of \nData Model. So it means it respects all existing objects, their columns, their names and so on. So when you operate \nwith OData, as well as when you operate with Data service, it uses Data Model. So it uses information about existing \nobjects, columns, references and access rights restrictions.",
      "chunk_type": "paragraph",
      "chunk_index": 8,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 116,
      "token_count": 142,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 8
      }
    },
    {
      "chunk_id": "02ba1ab4f688b9ebce5d2a022545aaef",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nOkay, so depending on what operation you need, you have to select the proper HTTP method, Get is used to select \npost for inserts, patch for updates, and HTTP Delete is used to perform physical delete operation. I will show you a \ncouple of examples and also you need to know that we have a lot of interesting documentation samples here. And \none of the good ones is creation API documentation hosted at Documentor, get postman. Com. This is one of the \nbest sources that you can find for OData. I plan to show you examples with OData 4. As you can see, first of all, we \nhave to make authentication correctly. Then we can do different queries and different examples. So depending on \nyour task, you may find a corresponding sample here. And also we have a lot of samples to make different filters.",
      "chunk_type": "paragraph",
      "chunk_index": 9,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 181,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 9
      }
    },
    {
      "chunk_id": "b26f763f9792f420f709448096c27fbc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nYou see, for different filters there are special expressions in let's say ODATA language. And so you can find a lot of \nexamples here. Even batch queries Supported Batch queue means running single query with several parameters. \nAnd each parameter explains to a system how to run a particular operation. So it can be useful if your plan is to run \nmany data operations with one single query. So batch operations are also supported. But we can do it. Let's not go \ntoo far. And I understand that probably not all of you will start your integration at all. And this is something that you \njust need to know and let's say get familiar with it. You will see how it works. So let me show you examples. My plan \nis to make some selection of data. We have some examples of data records.",
      "chunk_type": "paragraph",
      "chunk_index": 10,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 10
      }
    },
    {
      "chunk_id": "a37bf1e0a9281c48d5c40f05c0168dcc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nLet's read data from our reality object, but with the help of all data. First of all, I will use integration tool, I will use\n\n--- Page 3 ---\n\nPostman app and my yesterday cookies are not working anymore. They will not help me to run queries. I can check it \neasily so we can Try to run our web service and as you can see we have 401 not authorized. It means that our \ncookies are related to expired session. So providing such cookies we will not be able to use any business methods \nany business logic methods of creation web services. So we have to get new cookies. I prefer to clear previously set \ncookies. We go to perform login operation again. Yesterday we discussed how to do this. We use special URL to all \nservice and its login method inside of a root part of our application.",
      "chunk_type": "paragraph",
      "chunk_index": 11,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 153,
      "token_count": 181,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 11
      }
    },
    {
      "chunk_id": "4795c90b5091e5461950e5607450a1d1",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe provide login and password. No any special data, no any special headers. You may find some information here \nlike authentication and some accept content type for C session. But it turns out to be not necessary to perform \nauthentication successfully. So let me show you here we have some hidden headers made by postman like accept \ncontent type, application JSON and so on. But so I prefer to keep it as is by default. And we have login and \npassword. Originally we have no cookies. So let's try to get new session for us. Yes, we got it. 200 no errors. So \ncurrently we have set of cookies enough for us to perform inner queries. Okay, we can create new query and our \ntask. Let's keep it easy and keep it simple. So we will try to read data.",
      "chunk_type": "paragraph",
      "chunk_index": 12,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 12
      }
    },
    {
      "chunk_id": "457d37eca21d96b003c8341329678ce9",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe will have to make a selection of data records and we will make it get HTTP query. Let's do this. So let's go to \npostman, create a new get query. We have to use our address of our app with 0 alias here and then we can look at \nthis example or we can look at this document or get postman.com examples. So we need to do selection. And our \npart for odata web service is odata here. So it's a name of odata endpoint then/in odata4 we should use just entity \nname here. It's not obvious that collection one is entity name. And here you can see that it's also not so obvious, but \nmaybe you can find examples. Yeah, here you can see an example. So it will make it clear how we can do this. So I \nwill use an example with my USR realty.",
      "chunk_type": "paragraph",
      "chunk_index": 13,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 192,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 13
      }
    },
    {
      "chunk_id": "acd3f1083d90ab5c477c6b25d1529c57",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIf I provide no any parameters, system will try to read all of the data with all of the records, all of the columns. Let's \ntry to do this and run send for get queries we do not need to use BPM CSRF protection. So for get queries, no cross \nsite request forgery protection needed. And you see it took significant time, almost six seconds to run. And as a \nresult we have Some JSON body with different data records about our reality record saved in database. As you can \nsee all of the columns, a lot of unnecessary data. But that's how it works. If we provide no special parameters. Now I \nwill show you how we can make it more interesting and more useful. We can use different parameters in our script in \nour query.",
      "chunk_type": "paragraph",
      "chunk_index": 14,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 140,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 14
      }
    },
    {
      "chunk_id": "1023ccfc5c842c787942cdbd1a4eb0a5",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd let me show you for example parameters for selecting data collection instance selected fields. So here I can see \nan example and it means dollar select so question dollar select and then we have columns with comma separated \nvalues to get necessary columns. So I'm using this example, you can use this example and let me show you how we \ncan do it. So question mark to switch to parameters Dover select is parameters specifying column names that we \nplan to use. Don't forget we have to use column codes, not titles USR name USR price USD maybe created on. So if \nyou want you can get more. It's possible to use lookups in order to get corresponding names of type or name of a \nperson who created the record. But now I try to keep it simple. So this is example of how we can run queries.",
      "chunk_type": "paragraph",
      "chunk_index": 15,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 177,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 15
      }
    },
    {
      "chunk_id": "5fde7fbb05b1e70d415b5e2a435aaeca",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nYou see only requested columns. Now here and we can see all of the data. We can do some limitation. So we can \nuse and another parameter dollar top three for example. And when we do such selection, it will read only top three \nrecords for us. You see on the top three records you can use sort, you can use filter. We can use x order by in order \nto organize some sorting. We can use special parameters to select only one specific record but filtered by ID a lot of \nother options. So if necessary you will be able to do this. And I try just to keep it simple and quite useful for you. So\n\n--- Page 4 ---\n\nhere is an example of a get query to read some data. So you can try to do it even in your browser.",
      "chunk_type": "paragraph",
      "chunk_index": 16,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 171,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 16
      }
    },
    {
      "chunk_id": "21d926b9f84b3f830f8f3cf11c0770a1",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIn case if you will try to run such query in your browser, you do not need authentication because usually your browser \nis already authenticated in creation and you keep running session running pages of your creation in your browser. \nAnd that's why you don't usually need to prepare separate separate authentication for it. Okay, I think for selection it's \nquite clear. So let me show you how you can do insert data. I need to use almost the same set of parameters but for \ninsert. As you can see here we have post to add data. Let's do this. We can also look at examples for post and our \nURL will be quite simple. We will just provide post and this URL which includes our website zero application Alice \nOData is the endpoint for OData Web Service.",
      "chunk_type": "paragraph",
      "chunk_index": 17,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 141,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 17
      }
    },
    {
      "chunk_id": "71bdfcf3236af237f0e1f4a552bd19e7",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThen usr realty is also part of endpoint and it gives information to data what exact object you plan to operate with. \nThen I have to look at body row JSON and we have to provide some data for example USR name. This is mandatory \ndata from all data for integration it will be our name USR price USD okay, so you can see we have some data here. If \nwe try to run a post query without CSRF settings we will get 403 because for post query we must perform BPM CSRF \nheader we must put corresponding cookie value. Please carefully copy cookie value including some dots if they \npresent. So it's important in this case our insert will work. Okay? No, it tells that comment doesn't exist. Okay, it was \nmy fault because common name is USR comment. Okay, everything is working.",
      "chunk_type": "paragraph",
      "chunk_index": 18,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 176,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 18
      }
    },
    {
      "chunk_id": "9c9d82ee67ed25c26ef3ce411e402adb",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nNow we can go to our main app, sort by date of creation and we will immediately see that our data was added and \nwe can also check column values. Here you see price was added, we see column was added correctly. But what we \nreally interested you can see the type and offer type were set by default. It means our object model worked well for \nus and moreover our object model also supported all event handling provided with help of start signals. Now you \nsee three realty visits were already planned for upcoming days. So all business logic that was designed and \nprogrammed with the help of event handling with the help of start signals it will work for ODATA as well and server \nside handling like we did to validation for very big prices will also work. Now let me show you how it can look.",
      "chunk_type": "paragraph",
      "chunk_index": 19,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 19
      }
    },
    {
      "chunk_id": "f481c3d21fce99272f33201e64ecbb54",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo let's try to add very big number and it will be more than 1 billion. So we will see how system will react on this \nattempt. Now you see we have a quite rude error and this is error 500 internal error. But we have error text which \nmeans we intentionally erased such exception. We provided error message text of what is wrong and of course \nphysical insert was not done so we can read data, you see no new records created. So this is example how you can \nuse old data for your tasks and it will be really attractive for relatively simple tasks for your future integration needs \nwhere you need to transport not so many data records. If your task is to transport millions of rows, possibly such \napproach with running separate queries for each record will be not very effective, not very efficient.",
      "chunk_type": "paragraph",
      "chunk_index": 20,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 173,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 20
      }
    },
    {
      "chunk_id": "20ee707f8b8db119da5a543af585ddd1",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIn case if your task is to transport huge amounts of data, you have the only one option. This is your own \nprogramming of such data and your own parsing your data structures and your own database direct operations and \navoiding use of object model. Because when you use object model, you also support all of the object events. It \nworks not so fast. And for example, when we did insert with the help of postman, it took almost 180. No, in total it \ntook a bit longer. You see, we have some additional cost for preparation of the query. So it took 300 milliseconds. \nAnd it's important because if your task is to transport like 1 million of data rows, if you spend 300 milliseconds for \neach one, it means you will wait for several days and this speed probably will be not suitable for your customers.",
      "chunk_type": "paragraph",
      "chunk_index": 21,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 183,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 21
      }
    },
    {
      "chunk_id": "c87af963d98ddad48e5a99dc3142645d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 5 ---\n\nSo you have to search for a better solution. So in case of big number of records to process, in case of very, let's say, \nhard speed requirements for your solution, the only suitable option is your own web service with your own data \nformats, your own direct database management without use of object model. But in simple real life scenarios, I think \nall data will work well for you. And it's relatively easy because you see it's not so hard to build such query to run it \neven when your third party app is used. So you can do such programming. And also you will get response data in \nJSON string, so you can easily parse it, you can easily extract corresponding results that you may need. Here you \ncan see JSON objects and you can also get corresponding values from here. So it's very suitable for beginners.",
      "chunk_type": "paragraph",
      "chunk_index": 22,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 156,
      "token_count": 186,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 22
      }
    },
    {
      "chunk_id": "da9d09c8ce2c74d30afc2621ae9f99b5",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd for some tasks I think it will work perfectly. But for some other tasks you may find that all data is not enough, \nmaybe because of hard load conditions you will finally realize that our data is not going perfect with hard, I would \nsay hardwood big amounts of data. Maybe you will need some more complicated scenarios with reading data and \nperforming some calculations like preparing reports and running it with third party app. And you will need some \naggregation, some complex filtering. In this case, all data probably will be not the perfect solution. And data service \nmay work better. For data service is created by creature developers, not by Microsoft. And this is unique to creature \ntool.",
      "chunk_type": "paragraph",
      "chunk_index": 23,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 124,
      "token_count": 147,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 23
      }
    },
    {
      "chunk_id": "b9ac47a84bf83d49bfc6a5ef8f897fc2",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo it's appropriate way of operating with data using creature server side, it can do all the same operations like \ncreate, read, update and delete data and but it can do it a bit more efficiently. And also it supports different filter \ncondition macroses and it's much more rich when you need to select data from different tables, perform some \naggregations, perform some complex filtering. I will demonstrate what data service can do. And first of all I need to \ntell you the data service is mainly Used by inner creation client side pages. Each time when you operate with any list \nor edit page, you will see data service web service queries. You will also see that payload for that queries. It means \narguments that you need to transport. Payload is quite complex. You see more than hundred of different settings \nand if you preview.",
      "chunk_type": "paragraph",
      "chunk_index": 24,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 149,
      "token_count": 178,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 24
      }
    },
    {
      "chunk_id": "ff8c9f949658d275813084b2a4c1c390",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if you view source, you see a lot of settings and parameters that can be passed as arguments for data service. \nBut it also has a response with a JSON. So now you see JSON string which can be parsed and such JSON data not \nso hard to operate with. You can easily get corresponding values out from your results. So Data service web service \nmaybe can be suitable in case if for some reasons old data doesn't work for you as you expect. I will show you \nexamples of data service but first I wanted to mention that it's used inside of creatio pages. So data service was \ndesigned for inner creation data operations with client side. All lists and all edit pages are using data service to get \nor to modify, insert, update any data record.",
      "chunk_type": "paragraph",
      "chunk_index": 25,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 142,
      "token_count": 165,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 25
      }
    },
    {
      "chunk_id": "c05dc5941848b373e0b29eca2402d93a",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo in documentation you will find that data service is promoted as integration tool. So it's a restful service. You can \nuse third party to compose queries for it. And here it's promoted and advertised like an integration tool. But in reality \nit's not so integration oriented, but it is say platform UI oriented. Because all UI pages are working with the help of \nthis web service. I will show you some advanced features that this web service supports and let me hide some \nunnecessary columns. So my plan is to show you special types of columns called aggregate columns and also a bit \nlater aggregate filters. So aggregate column can make some calculation over connected data records. And such \nconnections will be done with the help of main record. Let me show you what I'm talking about. So each reality \nrecord may have number of visits inside.",
      "chunk_type": "paragraph",
      "chunk_index": 26,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 179,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 26
      }
    },
    {
      "chunk_id": "22d1606d21e31e9533f3eb319e88fb4f",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 6 ---\n\nRecently created records are having more visits because we already had automatically creation for them. But also \nwe have. Oh, we don't make any action to add the data director here. Okay, so we have some examples which already \nhave created data records in visits detail. And for each reality record we have number of visits, connected detail \nrecords. So we can make a career column. We can make an aggregate column which will simply calculate number of \nconnected records. This is one of the easiest possible aggregate columns that we can make. So let me show you \nhow you can do this.",
      "chunk_type": "paragraph",
      "chunk_index": 27,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 110,
      "token_count": 132,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 27
      }
    },
    {
      "chunk_id": "4e468478fb956d676226a47552ba5c9e",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAdd the columns and instead of working with traditional set of columns we have in main object you can go to related \nobjects and then we will see all objects that are available for us according to lookup columns from main object and \nalso we will see reverse joins. We will see other entities that have lookup columns pointing to reality. In my case this \nis realty visit. We have different options how to select data from it. And in last versions we have also advanced \nexamples like reading top one record. For example, we can read top one comment sorted by date of creation. Or we \ncan see top one customer who is specified in recent visits and so on. In my case I try to keep it simple. Let's look \nonly at number of records of connected visits and click select.",
      "chunk_type": "paragraph",
      "chunk_index": 28,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 146,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 28
      }
    },
    {
      "chunk_id": "2db6d4c3ccd4ed1ae50279392e544d11",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIt's also possible to specify special conditions to select data. For example, we can only calculate number of records \nthat are in future or only visits where contact is specified. So you can do different conditions here. In my case I also \ntry to make it easy and calculate total number of visits. And we can make the caption here visits count. So this visits \ncount will be our title for new created aggregate column. Then we click save and now you see new column which \nshows us some data. And for each separate reality we have some calculation. It's interesting to mention that this \ntype of calculation is also performed with the help of data service. Moreover, such calculation is performed with the \nsame query where a main data record is selected.",
      "chunk_type": "paragraph",
      "chunk_index": 29,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 136,
      "token_count": 158,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 29
      }
    },
    {
      "chunk_id": "ac24f24e854fe64e11ebf41a440d7e22",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if you reload the data using this update refresh button, you see only one query was executed and if you go deeper \nin payload you will see that our column for calculation of aggregate number is also represented to the standard \ncolumn. Here we have some column path for it, some setting for Type of aggregation. Aggregation Type 1 means \ncount and that's how system knows what to calculate and returns as some calculated number. This it was example \nof aggregate column and it can be really useful. And you should understand that this selection is not performed \nfrom reality. This column is obtained as a result of subquery from reality visits. And I want you to see one more \nfeature called folders and here we can make additional folders select and add the new folder here.",
      "chunk_type": "paragraph",
      "chunk_index": 30,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 141,
      "token_count": 162,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 30
      }
    },
    {
      "chunk_id": "3ffb6d3e9cba9007fa4f7f077038af0b",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo in general folders work here like search folders in your outlook. So here we can specify some name and the filter \nconditions that will be useful for us to select only some searching data, not all of the data from our list. Let's call it \nthree plus visits. So let's imagine for some reasons we need to look at realty records where we have three and more \nvisits created. We are not interested in realty records with no visits. So we can make such a name here, save it. Then \nwe can provide filter conditions for this folder. So now I'm planning to show you so called aggregate filters. We \nalready saw aggregate columns and you understand that they represent result of subqueries but calculated with the \nsame main query.",
      "chunk_type": "paragraph",
      "chunk_index": 31,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 134,
      "token_count": 160,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 31
      }
    },
    {
      "chunk_id": "896135f78060624bf48c1a1980f43790",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd aggregate filters will be used for selecting data applying conditions on connected records, not on reality data \nbut on connected records. In my case I plan to select only reality data where this visits count is greater or equal to\n\n--- Page 7 ---\n\nthree so we can make condition and here we have to select connected entity. So not just dropping down here \ncontents of reality columns. We have to click on this plus in order to select connected entity. In my case connected \nentity is real and the aggregation type will be just quantity and also we have alternative options like maximum or \nminimum date for creation or modification. If we had integer or decimal values there then it's possible to calculate \naverage price maximum or minimum.",
      "chunk_type": "paragraph",
      "chunk_index": 32,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 133,
      "token_count": 151,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 32
      }
    },
    {
      "chunk_id": "881e928e132594db8dd71b968a04e468",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo in my case I will just do quantity calculation select and we have condition count greater or equal three that will be \nour filter condition. We also can make additional filters here like counting only visits in future or counting only visits \nwith not empty comment. So whatever you think it will be useful you can do here. Then we save it and that's how we \nsee result of this filtering. So all data shows us all reality records. This search folder shows us only records which \nfollow corresponding filter conditions. Such filters are called aggregate filters and we can now go again to network \nand reward the data to see that our payload also has special filter condition. And this filter condition includes \ninformation that we use aggregate function.",
      "chunk_type": "paragraph",
      "chunk_index": 33,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 134,
      "token_count": 151,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 33
      }
    },
    {
      "chunk_id": "f3bf89430fa29f05f95f66c55a765967",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe use count for our aggregation so it will do selection only of records where some sub select some count of \nconnected data is greater than certain right expression and we have just value three here. So my example is to \ndemonstrate that data service web service is capable not only to read plain data from the data sections, but also it's \ncapable able to calculate aggregate columns and to use aggregate filters and you can use data service for your \nintegration. But I think it's really hard because you will need to have a good make already good made examples to \nmake it work. So if you make corresponding queries in your browser then you can steal all necessary parameters. \nLet me show you how we can do this. We can copy request URL from our query that we spotted in our network tab.",
      "chunk_type": "paragraph",
      "chunk_index": 34,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 168,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 34
      }
    },
    {
      "chunk_id": "392f34cc536d5cd5d13454042ed36232",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThen we go to postman create new actually you should be careful because data service is usually working with post \nqueries only. So we go to postman. Regardless of the operation we will use post query and paste this URL should be \ncareful. Okay Paste URL we have a huge body. We have go to payload view source select everything copy then we go \nto body here this is row JSON and we paste this big body it's really hard to analyze it so we can use beautify tool to \nsee it in a more structured way. So now you see we have a lot of options here that are used by data service and \nrequired here to be present. And as you can see I did not type them manually. I only used existing example from my \nbrowser console.",
      "chunk_type": "paragraph",
      "chunk_index": 35,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 164,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 35
      }
    },
    {
      "chunk_id": "a2fdc4bf4abd8e5c2a74946dc54e4e8c",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThis is a post clear so we obviously will go will fail into CSRF protection if we do not care about it. So BPMCSRF \nheader and corresponding cookie value you should get it carefully copying full value and pasting it here. Now we will \nsuccessfully run our query, we have some valid response JSON body and we see set of records, we see set of data \nand in general if you run something like this from third party app then you'll be able to parse your data and you'll be \nable to analyze it and get corresponding numbers or other columns if you need it. Adrian is asking is folder the only \nway to go to Advanced filter in Freedom ui? Yes, Currently we don't have any separate advanced filters for data \nselection, so developer decided to keep it saved into folders.",
      "chunk_type": "paragraph",
      "chunk_index": 36,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 145,
      "token_count": 168,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 36
      }
    },
    {
      "chunk_id": "7eb67f2d56e07652901a4d023b47fa75",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIn Classic UI we had an option to keep such code advanced mode and make this filtering like flying in the air without \nlanding anywhere in your system. But I personally think that this kind of advanced filter is not so good because once \nyou take time to build it, once you make complex conditions there is a highly likely situation then you will need it to \nsave. So developers in Freedom UI decided that no advanced filters anymore. If you need some complex filtering, \njust mentally prepare yourself to save it as a folder. It's not a big deal, not a trouble. And such folders usually have \nquite strict permission settings. So when you create a folder only your user will see it so it will not create too much\n\n--- Page 8 ---\n\nof garbage records seen by anyone. Only your user will see such records.",
      "chunk_type": "paragraph",
      "chunk_index": 37,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 173,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 37
      }
    },
    {
      "chunk_id": "dbd8b27a082f83c246a18b76b2190bd7",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIf you don't like it you can also remove it. So I think it's not a problem. Thank you Adrian for your question. And yes I \nagree we have some changes between Classic and Freedom UI and it looks like such changes were discussed so it's \nnot a real decrease of some important functionality. Thank you Adrian. So this example shows that Data Surveys is \nmuch more capable in comparison with ODATA because you can use more complicated calculations for columns for \nfilters and everything is going with just a single query. How we did here and demonstrated in Postman that it works \nperfectly in real life. Your integration will include not but one or two queries in real life I think you will need tens or \neven more queries to start. So it means that you will have series of different queries.",
      "chunk_type": "paragraph",
      "chunk_index": 38,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 146,
      "token_count": 170,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 38
      }
    },
    {
      "chunk_id": "2aa9fbbaa08dce43c0642e68d2bd90df",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nYou will need to remember data and save it somewhere. And in general it requires some quite strong professional \ndeveloper skills and architectural understanding of what you are doing. In general, I recommend you to run queries \nthat will not return you millions of records. It's better to operate with data using some portions and both ODATA and \ndata service have their own limitation. So we can find some limitation. Number of requests is unlimited but \nintegration options. I saw some information about it that we have a limitation about 20,000 of records per one \nselection and the same limitation will be applied for data service. This is limitation for OData and data service has \nvery similar limitation. But I just suggest and recommend you to operate with data with some smaller portions.",
      "chunk_type": "paragraph",
      "chunk_index": 39,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 136,
      "token_count": 160,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 39
      }
    },
    {
      "chunk_id": "c03aeb3edf5a5cc153737d382fdfeb9e",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nKeep some logging by yourself so it will be easier for you to detect and understand how actually it goes and do you \nhave any serious errors in your integration. So it's like a programmer task, but it's possible and in complex projects \nwe also do this and it works well. So let's move on. We already studied how third party app can operate with creatio \ntools and odata and data service are already present at creatio server side so they are already prepared for you. So \nyou only have to program at third party application to correctly call such tools and it will work for you. Now I wanted \nto show you an example how we can run third party web services from Creature and also how to do it with no code \ntools because no code is really attractive.",
      "chunk_type": "paragraph",
      "chunk_index": 40,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 144,
      "token_count": 165,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 40
      }
    },
    {
      "chunk_id": "a0523d7fb2abd31083eab7ee94123718",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIt takes very little time to develop and gives quite quick and valuable results. Let me show you. So let's imagine we \nhave Creature app, we have different sections, data and so on and we have some third party application that we \nwant to call and to use its data to perform some data transfer. Let me show you some example of it. We have a node \nwith REST API samples so we can use something like this. Let me show you. This is a REST API URL call that we can \nsend. This is a GET query. You can easily do it in your browser. Luckily it does not require any authentication. So it's a \nGET query performing with some kind of URL. No initial arguments but we have some response.",
      "chunk_type": "paragraph",
      "chunk_index": 41,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 135,
      "token_count": 158,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 41
      }
    },
    {
      "chunk_id": "8cf032cee699417e9ba016f4a8bc5081",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nJSON body this JSON body is also shown here for us and this JSON body represents some prices and I need to tell \nyou some physical sense of it. ID bank is one of the banks in Armenia and they sell gold bars, gold plates starting \nfrom 1 gram gold to up to 12 kilos gold, big gold slab and you see their prices are in local Armenian currency, \nArmenian drums. But in our case it's doesn't matter so we only want to practice here and also I want to show you \nsome additional example. Not only just get couple of data values from third party app but also to show you how you \ncan use no code tools to process collections and to get sets of some data records, how to store it, how to operate \nwith it.",
      "chunk_type": "paragraph",
      "chunk_index": 42,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 142,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 42
      }
    },
    {
      "chunk_id": "a176b2134e59218f34d8c09351b8c8fb",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 9 ---\n\nSo let's imagine we have a task to regularly get gold prices from this URL, from this API, save it in creatio and make it \npossible to run multiple times and correctly update such prices. I will use only no code tools for it and you will see \nhow we can do this. Also you may reproduce it just during today's session. So let's start. We have URL and it's nice if \nwe have some description of this URL. So generally we have it but in my case it will be really simple so I did not really \nneed it. But normally when you work with some kind of integration you will have this kind of explanation of how to \ncall corresponding query, how to transport some parameters rate go. Okay, now you see example of query, you can \nsee parameters, you can see requests and so on.",
      "chunk_type": "paragraph",
      "chunk_index": 43,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 155,
      "token_count": 184,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 43
      }
    },
    {
      "chunk_id": "bde4b3ab471d5021320d76878cfb780b",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd in my case so I can also share with you this is kind of documentation but the most important we need example \nof call which works for us. Luckily we don't have any special protection, security or authentication necessary for this. \nYou may also find a lot of other sources with similar functionality like currency exchange websites, like weather \nforecast websites, like other regular date that could be commonly interesting for people. It's usually shared without \nany special restrictions. In my case this doesn't require any parameters, any input arguments. So we can do it quite \nsimple and I think that simple example is better for beginners just to get started. So we have this URL and then I will \nexplain how we can work with it. First of all we need to go to studio workplace and find web services section.",
      "chunk_type": "paragraph",
      "chunk_index": 44,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 146,
      "token_count": 169,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 44
      }
    },
    {
      "chunk_id": "b26948386c3b5395209659b22c843dbc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe will properly register our new third party web service here and then we'll be able to call this web service from our \nbusiness processes with the help of call web service item. This will not require actual development skills, but it \nrequires some engineering knowledge and understanding of HTTP queries and HTTP methods type and just a bit of \nunderstanding of JSON string and you will see that it's not very difficult. So let's do this add new web service when \nwe Created system uses current package system settings. So when we provide an example of a full web service \nURL, it parses it and creates corresponding web service setting and tries to save it. We need to take care about the \nproper package to save. Now you see some phantom packages which we can't really find in our configuration, so \nlet's ignore them.",
      "chunk_type": "paragraph",
      "chunk_index": 45,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 45
      }
    },
    {
      "chunk_id": "c63fac6907903a65ba0e2d5e2a3f16d4",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThis is classic package because our current package system setting points to it. But my plan is to save our data to \nfreedom UI realty package. Let it be here. This URI is like a main part which was extracted from our URL and it will be \nused as a like base part of our web service and then we can have many different methods. Method addresses will be \nadded to our main web service URI address. The code is generated by app so let's call it something like gold bar \nservice name will be displayed and the code will be used for configuration saving into a package. Finally, we will \nhave a special type of item saved directly to the proper package. So you don't need to care about how such setting \nwill be saved in our configuration.",
      "chunk_type": "paragraph",
      "chunk_index": 46,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 142,
      "token_count": 163,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 46
      }
    },
    {
      "chunk_id": "aad1bec50bb456c2474ae2b68cbcc86d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThis will be saved as special metadata directly to the package. And we have a method here, so let's save it first. Now \nyou see configuration section and let's go to all items. You will see new type of item called web service and it's \nalready saved in our package. So all you can do is to open its metadata. You will see some low level text definition of \nthe setting like addresses and other settings and so on. But this is low level setting. You just need to remember that \nit will be saved in our package so you don't need to care about special transporting of it. Okay, we continue to do our \nsetup. System was capable to automatically parse our URL and get web service main part and method part and you \ncan see it's by default. This is a get method. Let's look at it.",
      "chunk_type": "paragraph",
      "chunk_index": 47,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 180,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 47
      }
    },
    {
      "chunk_id": "0bae71310c2bdad39c52fcd12ed0d770",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd in general one web service may have many methods so you can register them manually in order to use different \nfunctionality of the same web service. Get method the content type is JSON and response timeout is 5 seconds by\n\n--- Page 10 ---\n\ndefault, 5000 milliseconds means 5 seconds, no authentication necessary. And name is for display, code is for \nmetadata to save and method address is the most important property here because it represents exact part of the \nURL which will be used to add and make full. So when we do this we will make foo method address in our we have a \nfull method address in our lab service and this part was automatically parsed here. You can also type different types \nof Parameters like method parameter, method query value and also it's possible to transport additional data values \ndepending on the type of request you use.",
      "chunk_type": "paragraph",
      "chunk_index": 48,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 155,
      "token_count": 181,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 48
      }
    },
    {
      "chunk_id": "d045019e5859fb2175470b9006374788",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIf you use get query like in our case you only can use method address parameters inside of this URL. If you use post, \nit's possible to fill in post body request body and it helps to get much more possibilities to transport different data \nvalues as arguments to your web service. In my case I have no request parameters at all, but if you will do it \nsomething like yourself with different web services, you need to remember that we have all possible ways to transfer \ndata that is commonly used in the REST API. You can use address parameters, query values, header values. \nRemember like we did in our post query special headers setting. So it's like technical settings that will be passed as \npart of our query. So creation is also capable to provide headers and even cookies could be provided separately.",
      "chunk_type": "paragraph",
      "chunk_index": 49,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 170,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 49
      }
    },
    {
      "chunk_id": "bd522c43f71a6b6d1719df0529d18fa5",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if you do some operations with third party system which requires some authentication or requires some cookie \nfor like your user settings, then it's also possible to use it in your query. So it's very universal tool. In my case I do not \nneed request parameters in this example but I need response parameters. So let's save it again just not to lose \nanything. I will use response parameters first automatically. Let me show you. First of all I can run send test request, \nno parameters, no authentication so I just go and send it and I have a responsive JSON or in row HTTP . Of course \nJSON looks much more friendly for me and I will just copy this data and this is just an example of what web service \nanswered me. Okay, this is my response then I go to the method switch to response parameter.",
      "chunk_type": "paragraph",
      "chunk_index": 50,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 153,
      "token_count": 176,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 50
      }
    },
    {
      "chunk_id": "f0c2f09eb85be3102aa28305e37f9c7d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo my idea is to tell creatio how should I parse result data in order to extract specific values from it. So in my case \nresponse parameters can be added manually or we can use special very effective tool which is called quick setup \nand I will use example of my response body and give it to system in order to detect what are the possibilities, what \nare the possible values that we can get out from this example. So I will use setting of response parameters with the \nhelp of example in JSON quick setup example of response in JSON of course I have to paste my example of JSON \ndata obtained as a result from my test request. Then I click next System was capable to parse my data.",
      "chunk_type": "paragraph",
      "chunk_index": 51,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 134,
      "token_count": 147,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 51
      }
    },
    {
      "chunk_id": "2a2991f73b15fe4ca19067bddb66388f",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAs you can see it was it detected that I have two collections one is called cash sell it list of sell prices so bank sells \ngold bars and cash byte it looks like they have this data. But zeros tell us that possibly they are not really planning to \nbuy anything. And it's just like useless part of the data for us. So we can select what part of data is interesting and \nwhat part can be skipped because in our case we do not need it. And this is a very good example because in my \ncase I do not need cash buy part, but I need cash sell. Okay? And we can select only part that is necessary. It's \nimportant.",
      "chunk_type": "paragraph",
      "chunk_index": 52,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 126,
      "token_count": 144,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 52
      }
    },
    {
      "chunk_id": "a959e18b59d4dea9b7b5b521c0476afb",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThis is very important because in real life examples, for example, you can call some foreign currency exchange rate \nservice and you know, we have almost 200 of different world currencies and you may face maybe 4 or 5 or even \n1000 of records, 4 or 500 or thousands of records with different values and parameters as response. So it will be \nreally important for you to select only parameters that you really need to get from results of web service. Because \nsometimes web service result body is quite excessive, including a lot of information that you don't plan to use or just \nnot useful for you. In my case, I am interested in cache cell list and I will save it. Okay? So this helped me to avoid \nmanual registering of parameters. It's possible I can create such parameters manually. I can reproduce everything by\n\n--- Page 11 ---\n\nmy hand.",
      "chunk_type": "paragraph",
      "chunk_index": 53,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 155,
      "token_count": 188,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 53
      }
    },
    {
      "chunk_id": "3aadb0dd879c25b809dbc314fa60ef19",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBut using this quick setup tool by examples is much more efficient. So I have a root item here which represents a \ncollection is array. And also it's interesting to mention that creature uses such thing called JSON path. JSON path is \na kind of address of a value inside of a JSON body. So this value helps to detect and get corresponding value out \nfrom JSON body text and creatio is using it to allocate and find the corresponding parameters. As you can see, it's \nbody parameter and inside of this array we have pairs of data weight and rate. Let's look at our data closely. Weight \nusually so it's shown as a text, but physically it looks like a integer number minimum is 1 gram and maximum is \n12,000 grams, which means 12 kilos. So we can afford to treat weight not as text but as integer.",
      "chunk_type": "paragraph",
      "chunk_index": 54,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 182,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 54
      }
    },
    {
      "chunk_id": "28d1f4346cffe3d23c2031bc11858b39",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBecause we see that for all data values here it will be nice if we have an integer so we can treat results as integer \nand system will be okay with it. But when we go to rate and see some examples sometimes. So in general rate is a \ntext and sometimes we see thousand separators and sometimes you see it even twice. So it turned out that this \nmechanism which gets data automatically with the help of data service works poorly with type conversion. That's \nwhy it makes sense to keep rate obtained as text. And if you really need to work with it, as with decimal, obviously \nthis is a price, so it should be decimal.",
      "chunk_type": "paragraph",
      "chunk_index": 55,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 121,
      "token_count": 140,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 55
      }
    },
    {
      "chunk_id": "83898dd384ae9d12a6fc211c9484735f",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if you really need so you can parse this data lately after you've got it from the web service and then later and then \nyou can save it as you wish. In my case I keep it simple. I try to not spend too much time on such data type transfer. \nSo I prefer to keep it as text. So it will be just a good for our demo. It will be not so suitable for real life calculations. \nBut later it will be not a problem for you to use date type conversion using. For example, you can use script task for \nit. If really interested we can try to do this. But I'm trying to, let's say save our time and to not to go quite far from our \ndata obtaining from web service.",
      "chunk_type": "paragraph",
      "chunk_index": 56,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 140,
      "token_count": 162,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 56
      }
    },
    {
      "chunk_id": "e0ac1424479f1eb59caf3de60ee2218c",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nOkay, so this example takes result data and parses it and finally will present our data as collection of data records. \nWe can save it. Save it. And this information is now saved in our configuration section. Now I propose to make a five \nminutes break. I promise not to go too far and then we will continue. So let's move on. And we finished on the \ncreating of our web service. Checking out that our web service was saved into our package. This is very important. \nAnd now we will use it. So what how we can use it? We can create a business process which will run this call web \nservice item. We will get response data. But we need to think of where we plan to save set of records with weight \nand rate information. We have only two possible options. One is memory.",
      "chunk_type": "paragraph",
      "chunk_index": 57,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 177,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 57
      }
    },
    {
      "chunk_id": "8a25297e4075463f24ed811d8b397365",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBut it will require some C sharp scripting for us in order to keep data in redis memory. For example, I prefer to make \nit more simplified and no code. So we will save our data into our database in just a simple lookup. This lookup \nrequires integer weight and text rate. We can easily create it ourselves in this package. So I will do it Add object. This \nis necessary to organize storage of our data. And this storage will be named USR gold price. No, we can do it parent \nobject but not base lookup because we don't need name and description. I will use base entity because it will only \ngive us standard parent columns and we can add business columns ourselves. So we will create integer usr weight \ncolon. It will be integer and one more will be text 50.",
      "chunk_type": "paragraph",
      "chunk_index": 58,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 58
      }
    },
    {
      "chunk_id": "a43fa17d3b8ffb8b967612021385c66f",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 12 ---\n\nThe minimum one usr rate will be our rate column text 50. You may ask me why text? The answer is because I do \ndemo of getting data in real life. We will need to save our text values first or maybe to use them and process before \nsaving with the script task and then we will use a decimal value to save finally converted value and in my case I went \njust to keep it as demo for you. So we'll save a text rate data as we get it from web service and that's all. No anything \nelse we can publish our object. As you remember publish always performs save first so we don't need to click save \nbutton. Save was performed and publish was done. Great, now we have this object already applied.",
      "chunk_type": "paragraph",
      "chunk_index": 59,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 59
      }
    },
    {
      "chunk_id": "88fb1e713233776cc5730eefe4d7757d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nOne more small step we can go to lookups and register this object as lookup. So we click lookups new lookup find \nour gold prices save it. So now we have this lookup we can open its contents but we have nothing there. We can \nopen properties and create data binding item and save it into our package. This is necessary to remember \nregistering of the object as lookup. This is mandatory step if you want to go to your lookups and find it when we will \ngo when we will deliver our solution to test environment. So now my gold prices object is ready and we can move on \nto work with processes. So we registered our web service and we can use no code solution with processes to get \nthis data from third party.",
      "chunk_type": "paragraph",
      "chunk_index": 60,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 139,
      "token_count": 159,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 60
      }
    },
    {
      "chunk_id": "2f59a527eb233f9fbf22aa08889b5a88",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe can create new process name it like USR yet road price main process this is main process because I also plan to \nuse sub process to parse my collection. That's why I call this processes main process. No initial arguments simply \nstarting our process by manual start and the first step we need to do is call web service process item and which web \nservice to call. We have our ID banking web service then which method to call? We have the only one method that's \nwhy system selected eight method for us automatically. We don't have any request parameters. When we switch to \nadvanced mode we can see response parameters and response is our collection with couple of values here also we \nwill get HTTP status code which will be useful to check different errors and analyze what's actually happening.",
      "chunk_type": "paragraph",
      "chunk_index": 61,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 145,
      "token_count": 165,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 61
      }
    },
    {
      "chunk_id": "58376e8ce3137abea32bd12f8b814ce8",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd sometimes full response body will be important because it will be it will include everything obtained from third \nparty without any parsing Boolean success property and probably that's enough. And we also have a SO request \nbody but it looks like this is an input parameter and only for very specific cases. So I don't know how to make a no \ncode example with this response request body so we will not use it now. Okay, so when we run this call web service \nwe can run it like get Gold prices. This item will finally run this query. Let's go to primary mode, get code prices and \nit's important results will be saved somewhere inside of this item inside of the response parameter collection. So we \nwill obviously have to process this collection somehow.",
      "chunk_type": "paragraph",
      "chunk_index": 62,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 139,
      "token_count": 160,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 62
      }
    },
    {
      "chunk_id": "d441c9cc99222548239f2f7428694c5a",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd first of all I will show you some error handling in case if our request finished successfully. We can turn this flow \ninto conditional flow by clicking on this change type button and then set conditional flow so we can name it okay \nand we can check condition. This condition will include just boolean success property. If it's true then we will go \nhere. Otherwise we will stop and we will have another terminate item code error and we can go from our call web \nservice to this terminate item. You can name it error means something is not good and we can just turn our flow as \ninto default flow. Default flow will be activated if no one from conditional flows worked for us and default flow will be \nour error handling.",
      "chunk_type": "paragraph",
      "chunk_index": 63,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 137,
      "token_count": 153,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 63
      }
    },
    {
      "chunk_id": "ede4396ec29524df50046bcd1f3dfc52",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if we not successfully code our web service, no need to try to perform next steps. We just need to stop our so \nabort our process and use a separate terminate item because it will be stored in our history of execution so we will \neasily understand that it finished with an error. Okay, but if everything works well, we need to think of the place where \nwe plan to keep our data when we first run it. Obviously our data table will be empty so no visible preparation \nnecessary. But when we run it next time our data will be not empty and maybe it makes sense to clean it with the\n\n--- Page 13 ---\n\ndelete data item. So I will do this delete data and this will be an item to remove data from go price object. And as \nyou can see we have kind of protection here.",
      "chunk_type": "paragraph",
      "chunk_index": 64,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 155,
      "token_count": 176,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 64
      }
    },
    {
      "chunk_id": "9768c9a21827dba1a5afaddb8baea140",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThis protection means that for delete data we must use some parameter. If we don't, this will not allow us to save \nprocess and it will show us errors. So we must use some parameters here. And this is kind of protection from \nunintentional delete of all the data. But in our case we intentionally want to do this. So we have to perform some \nkind of fake query which will be always true. And that's how we can make this correct condition to delete data. So I \nwill make a filter like ID is filled in for any existing record. This condition will be true and that's why I can use it. And \nit's quite easy and simple. It will not require too much resources from system to make it. So this will be an item like \nclear prices storage.",
      "chunk_type": "paragraph",
      "chunk_index": 65,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 144,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 65
      }
    },
    {
      "chunk_id": "f61eb52a17f1c2ff1c4005a60188c4c2",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo we delete prices from our storage and then we can use so we have a Collection and we have two options. To use \nno code approach with sub process to parse collection or to use C Sharp code in order to parse our collection with \nprogramming. Of course I prefer no code approach. Let's save temporary our current progress. Oh, it tells that the \nchange is saved. Cyclic change in packet hierarchy. Probably it's because of I forgot to make dependencies and \nsettings. Yes, it was my fault. Okay, it was unusual, but it was my fault. Well, it's because of current package system \nsetting was pointing to classic UI package. I have to switch to realty. Yes, modify my setting and save again. Now I \nhave no cyclic dependencies. Let's go and check our packages.",
      "chunk_type": "paragraph",
      "chunk_index": 66,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 140,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 66
      }
    },
    {
      "chunk_id": "910068755d1d006f0e6093a0e292537d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo realty package should be dependent from dev classic and dev classic package should not be dependent from \nrealty. Yes, looks good. Yes, looks good. Very good. So now no cyclic dependencies, no troubles. And this was just \nbecause of the package. So that's why. So we worked with process library. If you select a corresponding package, if \nyou start to create your process from here, then your process will be okay with the correct package setting. So \npossibly we have one more plus for creating processes from configuration section, but not from the process library. \nOkay, we have first now let's do not repeat this mistake again and we will select our package. Add one more \npackage. I need a sub process to parse my collection. The main idea how we can parse collection is to make a sub \nprocess and to use arguments as parameters.",
      "chunk_type": "paragraph",
      "chunk_index": 67,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 184,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 67
      }
    },
    {
      "chunk_id": "d42474ca88c21d0e748155102dc1834b",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo we'll use parameters and I was a process to accept collection data values and I will make my process name USR \nadd gold price subprocess. So it will be my sub process to add the gold prices. I need parameters because the only \nway to transfer data from main process to sub process is sub process parameters. One parameter will be integer. So \nI add the parameter which will mean weight integer input which make it makes it read only inside of my process. But \nI don't plan to change it. So I only plan to get it as input value no initial values. Save it. Another parameter is text 50 \nthe shortest one and it will be rate and it's also input and no initial value. So here we have a couple of values we \nexpect to get at the beginning of the process.",
      "chunk_type": "paragraph",
      "chunk_index": 68,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 149,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 68
      }
    },
    {
      "chunk_id": "1c17d87b18ca74f83207b29ef800a972",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nThen we will use our process and our process structure will be really simple. We will just use one add data item. We \nwill add data into gold price object add price and we will fill one record and only couple of values weight and rate will \nbe filled in very easy rate and weight. So rate will take its value from corresponding Rate text parameter weight \nClicking on this lightning button, we'll get its value from corresponding integer weight parameter. Please note select \nparameter window always filters available parameters according to the data type. So that's why we see only \ndecimals and previously we saw only text parameters. Okay, we have this stuff. So you see the sub process is pretty \nsimple and we can save it, close it, go back to main process.\n\n--- Page 14 ---",
      "chunk_type": "paragraph",
      "chunk_index": 69,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 142,
      "token_count": 167,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 69
      }
    },
    {
      "chunk_id": "0ef7d3639bcbc938e03562d5bf25db58",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nNow we will use an item called sub process and I will use this orange item and place it into my diagram. Normally \nwhen you want to run a single instance of a sub process, you just specify your sub process name and single \ninstance call means you have to transport. They are just pair of values and this means that you will run your sub \nprocess only once. But in our case we plan to work with it and parse collection with the help of sub processes. So I \nwill use special settings. Now please be careful and watch here what I will do now. For example, let's go with wait \nfirst. So we plan to turn this sub process into a collection processing mode. And this can be done by selecting \nspecial values here. And such values should be taken from collection.",
      "chunk_type": "paragraph",
      "chunk_index": 70,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 168,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 70
      }
    },
    {
      "chunk_id": "1cb4ce2936718b93129d0b8cbcec5245",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo I click on this lightning button, select process parameter and then I will select process elements and our get gold \nprices call web service. It returns collection and we have corresponding weight column in this correction. So I have \nto double click it. And that's how our sub process immediately turned into collection processing mode. And it will run \nas many sub process instances as many collection data records we have. And we have execution mode sequential \nor parallel. In my case, no need to run parallel sequential means one by one and we have input collection. We already \nspecified weight column for it. Now we will set rate column from process parameter rate double click. That's how we \ndo this. Run it in the background is not necessary here will probably only take some additional performance.",
      "chunk_type": "paragraph",
      "chunk_index": 71,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 141,
      "token_count": 164,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 71
      }
    },
    {
      "chunk_id": "e5df4c58c608c0432b4564306f9ead4e",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBut in here we can just run the process and we are interested that in finishing it fully synchronously. No strong \nreasons to run it in background creating some scheduler executed tasks. So we just can run it simply in a current \nthread. Okay, when it runs we can also call it like add prices. Okay, it prices and it will run ad vote price sub \nprocesses and we'll have as many sub processes as many collection records you found. So that's it. Our example is \nready. So it will be our happy finish item. This is our start. It makes sense to note and make names for all the items. \nIt will be like a documentation which makes it easy to understand and we have current version. Okay, let's Save it. So \nnow we have this process and we can start it from here or from process library.",
      "chunk_type": "paragraph",
      "chunk_index": 72,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 182,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 72
      }
    },
    {
      "chunk_id": "324ca45d107d627cde02119458544ccc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nLet's reload it by clicking on this icon and we have to start main process. Let's start it. But also before starting it we \ncan enable trace to be important for our debugging and we can also. That's it. Okay. Trace is the only one option \nsuitable for us. So let's run this process. Then we go to process log. We will see our main process started and it took \na bit longer than 1.2 seconds. And then you see number of subordinate sub process instances executed quite fast. \nBut we have approximately 11 items here. So we can check main process and open its execution diagram so we can \nsee how many times our sub process started. 11 starts, no errors and it looks like everything went fully okay. You \ncan also see trace data. We are interested in how exactly our gold prices were obtained.",
      "chunk_type": "paragraph",
      "chunk_index": 73,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 184,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 73
      }
    },
    {
      "chunk_id": "33aab30bdb4b1a6cfd7d6c541108558e",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo we can click on show trace data. You will see all the parameters in your collection. We can see technical \nparameters like response status, code 200 means everything is okay, full response body sometimes can be \nimportant. And it looks like in our example everything went smoothly without any errors. So this trace takes some \nadditional performance. But in general it's a good idea. And this trace helps you to understand if something goes \nwrong. And you will see exact parameter values, exact status code. So I recommend you to keep trace on if you want \nto support possibility of quick discovery of something if something goes wrong in your integration. So in my case \neverything went well and we go to lookups to see exact prices. So code, prices section, lookup list and we can just \ndisplay weight and then we can display rate, save it.",
      "chunk_type": "paragraph",
      "chunk_index": 74,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 180,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 74
      }
    },
    {
      "chunk_id": "99ecf7b8331d78a8bcb21e8e91102692",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 15 ---\n\nAlso it makes sense to look at the columns of creation, date of creation. Okay, and now you see we have all obtained \ndata saved in creation. Physically this is text. So if really needed we can use parsing. We can use some C sharp \nscripting to parse such values into decimal and then save them into corresponding decimal fields. But technical side \nof running queries and asking third party system and to return some data. I think it's quite clear in case if you have \nany questions, feel free to ask, I will be happy to answer. This is example how we can call third party apps. And at \nthe beginning of course you will need some example of a call some URL, example of parameters, maybe some \ndescription and documentation how to call this password public API. And you have all steps made with no code.",
      "chunk_type": "paragraph",
      "chunk_index": 75,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 155,
      "token_count": 184,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 75
      }
    },
    {
      "chunk_id": "777e6bb4e32787b4b2caab4c5bcca936",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd finally we have a process which takes probably less than hour to develop with all the explanations and we \nsuccessfully got our data. If we start this process one more time, you will see in our lookups, you will see new data. \nSo you see date in time was changed. So our contents of previously obtained records was successfully removed and \nwe have new data records inserted just seconds ago. This is also important when you develop your integration to \ncheck how it runs multiple times, because if it runs once, it's okay, but you should expect it to run regularly and it \nshould properly include the existing data and correctly operate with it. Probably removing it, probably updating it. It's \nup to you in case, if you have any questions about it, tell me please.",
      "chunk_type": "paragraph",
      "chunk_index": 76,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 140,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 76
      }
    },
    {
      "chunk_id": "aa6db2a1588d73c837626daad6a45608",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nMy next topic for today is to explain you how to use Clio tool and explain why you need it. So first of all I should \nexplain why we have some additional tools and not inside of the base platform. So previously we already had a tool \nthat was necessary to support developers and this tool was called Let me show you Delivery Tools and Workspace \nConsole Overview. So previously we had a special tool called Workspace Console and it's probably more than 12 \nyears old and it was used only for developers and only for developer tasks. Sometimes tasks were included based \nproduct preparation, processing resources, translations and so on. And finally it evolved into a complex tool with \nMany more than 50 different functions related to C Sharp sources, related to stored localization files, XMLs working \nwith file system, working with version control.",
      "chunk_type": "paragraph",
      "chunk_index": 77,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 173,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 77
      }
    },
    {
      "chunk_id": "689ef302c3c551eaecd1abd94d17bf93",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd so it has a lot of different, let's say quite technical purpose, which probably will be not necessary for end users. \nSo developers used it for a long time. But now this is an old tool which has its own disadvantages and developers \nwanted to make something new, so they made a new tool called Clio. You can find it in GitHub, ATF Clio. If you \nsearch for this, you will easily find GitHub repository. You can find its root folder and then you can see a list of \nowners or maybe authors or contributors into this tool. And you need to remember that most of them are Creature \nemployees, only some of them are outside of a company. So you see some strange users here and there are some \npeople from outside of Creation, but most of them are from Creature.",
      "chunk_type": "paragraph",
      "chunk_index": 78,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 146,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 78
      }
    },
    {
      "chunk_id": "9599e09e04348df47bc4fd95d7a0d2a6",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo generally you can consider as this tool was written by Creation in general, but this tool has open source code. You \ncan easily not easily, but you can analyze its source code. You can like propose your own improvements into it. You \ncan even add your own functions and also collaborate and helps to fix maybe some bugs and maybe to improve \ndocumentation and so on. So this tool is open sourced, so it's free of charge and you can use it at your own. This \ntool has also more than 50 different columns comments and I need to quickly show you how you can use it and why \nyou may need it. I will focus on the most useful examples that you may face when you develop your projects.",
      "chunk_type": "paragraph",
      "chunk_index": 79,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 134,
      "token_count": 153,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 79
      }
    },
    {
      "chunk_id": "f8b81d9b1a1f593fd15da6be57097905",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBut you should keep in mind that this tool was written by developers of base product, so they had their own reasons\n\n--- Page 16 ---\n\nand needs to operate inside of base product. And now you will see this difference. So let's go and I will show you \nhow to use it. This tool was designed to use by command line, so you should use some Windows or if you use other \nthis other operating system you should use command line for it. And first of all we need to check presence of this \ntool and you can find documentation here how to install it. So let's let me show you. You must install dotnet core \nframework on your PC if you want to use Clio.",
      "chunk_type": "paragraph",
      "chunk_index": 80,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 130,
      "token_count": 152,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 80
      }
    },
    {
      "chunk_id": "2fa83a85225ff772c9a108b5355afe49",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nI already have it dotnet tool list G this is command showing me existing installed dotnet core tools on my PC and \nClio is already installed here. Okay, I can remove it dotnet to uninstall Clio G It means remove it from my system. \nNow if we check we have no creature Clio tool on my PC. This is a common line utility. It's managed by command \nline parameters and the most important property of it. It operates with target creation system with the help of web \nservice calls. So Clio is managing creation by help of web services. It means that it can manage local or remote \ninstance the same well so unlikely to workspace console which required file system access and database access to \nyour creation. Clio requires only Internet network access to your creation.",
      "chunk_type": "paragraph",
      "chunk_index": 81,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 140,
      "token_count": 167,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 81
      }
    },
    {
      "chunk_id": "bf6bf8cf0f28fb10ce0e51c22fd4564e",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nOkay, let's install it.net sorry to install Clio G this is command that you can type in your windows command terminal. \nThis is two this is common to install Clio. It will install the latest version. Let's see what version we will have. Now of \ncourse this comment requires Internet connection so it goes to nuget searches for the last package which it can \nfind. And now you see the Last version is 61016. So this is current latest version of Clio. Okay, we installed Clio but \nnot set it up fully. We already can run Clio command to see plenty. Oh sorry, my fault. Plenty of functions that it can \ndo for you. So let me show you where is my scroll bar Here you see more than 60 different functions and I have.",
      "chunk_type": "paragraph",
      "chunk_index": 82,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 138,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 82
      }
    },
    {
      "chunk_id": "d79f1b88956070558fedcc72fc0fb0be",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nI have suspect that the most early created functions are at the top of this list and the most recently lately created \nfunctions are at the end of this list, you will not need all of them. So it's like a universal tool. It has a lot of different \nparameters, a lot of different comments. So I will show you the most important, the most practical that you may \nneed. And after installation we need to tell Clio what environments we will work with. Because Clio operates with \ntarget website and it needs to know URL, login and password. So we can use command clio show webep list and it \nwill show a list of registered applications that are already present on my disk and physically saved into this app \nsettings JSON file located somewhere in my user folder on disk. You see my previous attempts here.",
      "chunk_type": "paragraph",
      "chunk_index": 83,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 175,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 83
      }
    },
    {
      "chunk_id": "54cb3b932aa6b8cee1ead91a204e57d1",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo I already have some previous environments registered. I have to register my current environment. Clio reg web \napp I need to show you reg web app. Of course you need to know how to spell certain comments, how to get their \nparameters. So you can try to do something like this. And for some comments. Oh, doesn't show us. Okay, let's do \nthis like this. So for most of comments you can type minus question and you will see some error that it did not \nobtained, did not understand the command. And it will show you a list of all supported comments. Most of \ncommands have their short version and most of parameters have their short version. So in order to save your space \nyou can use shorter parameters. And the reg the app command is used to register your app.",
      "chunk_type": "paragraph",
      "chunk_index": 84,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 145,
      "token_count": 175,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 84
      }
    },
    {
      "chunk_id": "aeec8433d25c12538c9163b747aff24e",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo it will be included into this file and then you will refer to it by name. This is easier than providing URL, login and \npassword each time when you need to operate with target environment. So let me register my current environment. \nClear reg the web app. I already have some example, so let me type it. So I have D1 to do. Yes, this is my \nenvironment. Okay. L means login supervisor, P means password supervisor and my name will be D1. So this is how \nI do my register. Copy it for you so you will remember it and you will understand why I need it. So when I register my \napp. Oh, we have some additional troubles. And path environment list is net core. So we have some troubles in \nexisting app settings. JSON okay, it was not expected. Okay, show the list.\n\n--- Page 17 ---",
      "chunk_type": "paragraph",
      "chunk_index": 85,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 154,
      "token_count": 189,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 85
      }
    },
    {
      "chunk_id": "3ca0c4d3de4ddd61411084d85ee218bc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWow, we have some troubles in this file line 41. Probably because I have some older versions of such settings. Okay, \nlet's go where it tells users. What else? Users or user app data Local creation My user app data local creature. Sorry, \nsorry. Local creation Clear App settings JSON possibly I have some incorrect settings here or maybe outdated \nsettings. Oh, I have something like this, which obviously it doesn't look good and probably it's a result of some \nprevious stuff. It looks like I have some incorrect settings here. So okay, environments closed. Then here it's end of \nenvironments. Here is end of all stuff. Also I could remove my previous items here. So I have no environments. Now \nlet's try to ask it. Clear show web app list. No troubles. You see, everything is okay. Clear reg web app. Configure it \ncorrectly. Okay, great.",
      "chunk_type": "paragraph",
      "chunk_index": 86,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 195,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 86
      }
    },
    {
      "chunk_id": "1e7dead5b9835c7dfe7b754d004877f3",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo now we can do some simple operations with it. Cleoping and then we have different options. But the easiest way \nis to use E key for environment and then environment name. So this cleo ping will physically check availability of our \nweb service. And if it's okay, you will see yellow. Sorry, not yellow green color text. So ping was successful. One of \nthe functions that can be useful is restart. So you can use restart function. Restart comment clear restart ed1 this is \nfor restart of our app. You remember we used maintenance tools add on for this. But also you can use this \ncommand to perform restart. Usually it's safe and quite quick. You will see what is happening. Now our application \nis being restarted. It takes up to 10 seconds and sometimes you will need this restart as part of your development \nprocess.",
      "chunk_type": "paragraph",
      "chunk_index": 87,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 183,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 87
      }
    },
    {
      "chunk_id": "e9d911c72d06bfd80859ddb9628fa7ca",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nYou remember when we modified some objects, added new columns, we had to restart our app to properly apply \nsuch changes. So we had such scenarios in our training when we needed it. And simple log out and login did not \nhelp. Okay, so let's move on. We already started restart. We have a lot of other commands and you will see plenty of \nthem. A lot of comments. I will show you the most important ones. So from project development point of view, you \nneed to know that Clio can really help you with saving packages and loading packages. So you can use Clio to \ndownload packages. This one, this comment. Download packages from source environment. For example it can be \ndeveloper environment and then you can use install package. Let me find it. So we have download and we should \nhave upload. Push pkg.",
      "chunk_type": "paragraph",
      "chunk_index": 88,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 149,
      "token_count": 182,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 88
      }
    },
    {
      "chunk_id": "65efe923ac474985460f34c421ced605",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nLet me switch find it should be somewhere here. Yeah. Push pkg. It has also short command install. I don't know \nwhy developers did not show it here. Install command is capable so it should be shown here. So you see \ndocumentation probably is not perfect. And the install command loads our package to target environment. This can \nhelp us to organize CI cd continuous integration and continuous delivery with a single script that can be started with \nthe one step one operation. We can download and then we can install it. But also you need to know that create Clio \nhas more other columns. Sorry comments and some comments like we use for download or install are using \nstandard base product creation Web services. So system that we work with doesn't require any special setting.",
      "chunk_type": "paragraph",
      "chunk_index": 89,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 139,
      "token_count": 163,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 89
      }
    },
    {
      "chunk_id": "32dc94fb2413a438c90e57ae3fdb48f4",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBut if you want to use all power of existing Clio commands, you must perform special command and this command \nis named Install gate. This Command downloads from NuGet and installs in your target system special package \nwhich keeps DLL inside. And this DLL includes all necessary web services that enable this set of commands. So \nsuch web services, simply speaking, are parts of Clio to implement corresponding comments without this comment, \nwithout install gate, without additional package installed to your system, CLIO will be not capable to perform \ncorresponding commands. It will show you error 404, which means missing functionality in your target environment. \nSo Clio only runs web services at your creature. And if it fails to run web service that it needs to perform a \ncorresponding command, you will see this error. So let's try.\n\n--- Page 18 ---",
      "chunk_type": "paragraph",
      "chunk_index": 90,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 145,
      "token_count": 182,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 90
      }
    },
    {
      "chunk_id": "2f5f0a6386e4e29f3a39648404b23716",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nLet's try to run a command to install gate Clio install gate ED1 this is required in case if you want to enable full power \nof Clio commands. So in my case, I will do it in my source environment. This takes time because it Downloads \npackage from NuGet, it installs this package into your target environment. This package is called Clio Gate. So you \nwill see new package Clio gate in your system. And this package will have so called file contents and file contents \nwill include compiled classes for your web services necessary for Clio to work. Let me show you. So here we have \nconfiguration section. Okay, it looks like we have some stuff here. Let's reload the package. Reload configuration \nsection. We have some interesting information here. I did not expect it. It looks like we have some troubles with all \ndata for compilation.",
      "chunk_type": "paragraph",
      "chunk_index": 91,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 186,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 91
      }
    },
    {
      "chunk_id": "dfa0f97c1f7c8dcf86391a63ee467cad",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo system tried to compile and failed exceeded narrow try count work process. So our IIS prevented our system to \ncompile. Let me check. Did I detach? Of course, my visual studio was detached. Okay, I need to look at such \nquestions. And also we see some troubles with old data and probably it's file system issue. Okay, so now system \ntried to install and compile package named Clio Gate. I should expect it to see it here. No, now sort was performed \nwith this case insensitive sort. Clio gate is a package with functions that are necessary to run Clio commands. And \nyou see only a couple of data items here. Of course, it's not full stuff. So we go to file system, we go to our \napplication, go to our packages Clio Gate package.",
      "chunk_type": "paragraph",
      "chunk_index": 92,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 139,
      "token_count": 176,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 92
      }
    },
    {
      "chunk_id": "4ef05a5715c733c94661df2de8c5b348",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nYou can see its size 5 megabyte of executables not so little files Bin and here, here and here are DLLs included as \nfile content for this Clio Gate package. So such DLLs are used to execute Clio commands. They implement the \nimplement web services, install such classes into creature server side. So that's actually how Clio may work on a \ncertain environment and how Clio may create and implement new comments. Because if you want to run something, \nyour target system must be able to do this. Okay. So if necessary we can fight with it. It looks like I have not so much \ntime today to fix this configuration issue. My command to install Clio gate package was quite correct. So it looks like \neverything is okay. So now I can show you some examples how you can use Clio efficiently for project development.",
      "chunk_type": "paragraph",
      "chunk_index": 93,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 149,
      "token_count": 184,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 93
      }
    },
    {
      "chunk_id": "8ec23f301a9f81927d75c52108209720",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd this will be comments to save and load environment settings and Sorry, Save and load packages. Let me show \nyou. I already have another test environment. You probably forgot about it. So we have D1 Studio as development \nenvironment and D2 second was used as a target and the test environment. Let's check it out. It should be alive. So \nlet's go D2 it's used as test environment. So why it's loaded? I can also use Clio to. Sorry to register a new \nenvironment. So we load it here and then we will use it. So clear rag web app. I need to register D2 and I will call it D2 \ntest to make it clear that it will be my test environment. Okay, register it Clio show the back list. Okay, my D2 test and \nClio ping P D2 test. So.",
      "chunk_type": "paragraph",
      "chunk_index": 94,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 146,
      "token_count": 188,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 94
      }
    },
    {
      "chunk_id": "6016de8f21147b60b5add590b91cf328",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo I will check availability of my second environment and it looks like should be okay. Yes, looks like Bing is okay. \nHere is my second environment. So my plan is to show you the most useful usage of Clio for project development. \nThis is CI CD automation for saving and loading of packages. I already have examples of scripts that perform this \nsave and load. So let's take this one. Probably Clio download so we can download set of packages. Let's check out \nhow many source packages we have. So we have Dev Classic. Okay, here Dev Classic. Then we have USR Realty and \nalso we have USR Realty migration. So we have three packages here. USR realty migration and Source environment \nis dynamic one. So Clio download is the same as Clio pool PKG command and we can download set of packages.",
      "chunk_type": "paragraph",
      "chunk_index": 95,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 183,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 95
      }
    },
    {
      "chunk_id": "0d56b234f1cdd93242377785927cbaee",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 19 ---\n\nNot only one but several packages from source environment. Destination path is somewhere like this guided dev. \nOkay, let it be May 2024. So we will finally have a result of a zip file including all our packages. We can use this zip \nfile into next command which will be used for loading clio install the same as clio pool push pkg we will use source \nfile I will use on target environment D2 test and we need to use logs because it's important to see some technical \ndetails. So I will share such comments for save and load with you. It will be really important for you if you want to \npractice with it. And now let's check out how it works. We will remove unnecessary examples and this will be my \nsave and load example of CI cd.",
      "chunk_type": "paragraph",
      "chunk_index": 96,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 96
      }
    },
    {
      "chunk_id": "d41ea3e3ed0b148e8bc075ed56736156",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nLet's try first system will save three packages into gz files organized into one single zip file and then it will be done \nand as you can see it makes it as a one operation if you do save manually saving of an app or saving of a separate \npackage. So you will have to perform it with separate structure steps. As you can see it went but not so fully \ncorrectly. I will remove unnecessary files from my example the 7th of April so those are here. So here is our saved \nzip file. So it looks like save part went okay and may part it looks like I had couple of exceptions here. Let's analyze \nour logs.",
      "chunk_type": "paragraph",
      "chunk_index": 97,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 122,
      "token_count": 141,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 97
      }
    },
    {
      "chunk_id": "06c4b14cb210e2678db1f5812140a162",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo you see we have location packages more file descriptor more than one file app descriptor JSON what it is what \npackage it's about real to migration No, I don't know. So something wrong with application descriptors we can check \nit at our file system. Probably it's a result of something messing with package dependencies. So our realty has its \nown information of app descriptor yes, this is realty app. Okay, realty migration has its own app descriptor yes and \nour dev classic should have no dependencies from existing reality stuff and it should have oh we have app \ndescriptor extension.",
      "chunk_type": "paragraph",
      "chunk_index": 98,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 104,
      "token_count": 125,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 98
      }
    },
    {
      "chunk_id": "84e1af4a85c4d6a2ecc246d290119126",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSomething is strange here and it looks like probably system failed to work with it but it looks like it's not a big trouble \nand you see one more issue here parent schema and was not found yes, this is more serious trouble because it \nlooks like our target environment was not fully prepared to install our changes because it miss customer 360 app \npossibly previous error message that we had here previous message with this stuff here probably it was also \nmissing corresponding app and we used so our solution expects that target system will help customer360 in my \nexample customers current our target environment did not have customer 360 that's why we have this stuff. So in \norder to fix it of course we have to install customer360 first and then our solution next. In this case it will be loaded \nfully correctly.",
      "chunk_type": "paragraph",
      "chunk_index": 99,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 167,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 99
      }
    },
    {
      "chunk_id": "81c14ec47780b64036825d2e5855f6d9",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nBut now we can test our target environment. So usually we need to reload it. We can find our items like oh, we don't \nhave any, probably did not like it. Okay, we have to install customer360 here and then load our solution. So you see \nonly Dev Classic was loaded here and recent stuff was not loaded. Okay, let's try to install customer360 install. \nContinue. I did not enable file system development mode here because it's like a test environment and no any \ncreation, no any external ID. So let's install it. I install customer360, then I can try to load my settings again. That's \nhow we will see our working example. So I plan to show you fully correct transition of my environments. This is \ncustomer360 installation on my target system. As you can see previous results of manual load of package.",
      "chunk_type": "paragraph",
      "chunk_index": 100,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 147,
      "token_count": 184,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 100
      }
    },
    {
      "chunk_id": "28afb948a56c6225bbf3e26bd4b9e5cc",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nManual load can be done with new application and then install from file. Now we have successful installation. Great. \nIf we reload we will see customer360 app added. Yes, customer360 was added. Now we can try to install our stuff\n\n--- Page 20 ---\n\none more time here. Let's remove previous package. So we will. And one more thing before we continue. So this is \nnot so obvious, but when we developed C sources we used external editors. We have C code saved on disk only. And \nin order to make everything correct, we need to download all items that we develop manually inside of our \nembedded editors back to disk. And then we have to upload changes from disk. This is very important because our \ndatabase part of C Sharp sources may have old C source.",
      "chunk_type": "paragraph",
      "chunk_index": 101,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 140,
      "token_count": 170,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 101
      }
    },
    {
      "chunk_id": "4564dd16d792457ba5a8a957e1e1dfe1",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd if we ever try to compile our package on target environment, we may have very unpleasant situation when we \nwill try to compile old contents of C sources instead of actual one. So in order to make correct export of your \nsolution to test in production, we need to save everything on disk. Then we have to take everything from disk update \npackages from file system. Now you will see system will show us differences in C Sharp code. Because both \nexamples were written here and here were written with the help of external editors. This is very important. Now our \nsystem is ready to export. So let's do this again. Save and load. Thank you Adrian for your time. Yes, we are almost \nover. We will continue tomorrow with preparation for developer action and also answering your questions.",
      "chunk_type": "paragraph",
      "chunk_index": 102,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 167,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 102
      }
    },
    {
      "chunk_id": "699e875b81e9e54f7e60e8cc5a7cdff3",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIt will be not so hard and thank you for your time. So now I just plan to make it correctly with save and load and then \nif everything goes well, we will see our Apps we will see our functionality loaded to our target environment if \nsomething goes not as planned. This is also good because we will see some exceptions. You will see how we can \ntroubleshoot them. It's important to understand how you may do some fixes when your package is not installed as \nyou plan. Now you can see. Oh, do we have any errors? Yes, we had some errors here and it's interesting because it \nshould not be so we should not have any issues here. Possibly it's about data. Let me check here we have a log file \nand we have data insert issue.",
      "chunk_type": "paragraph",
      "chunk_index": 103,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 169,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 103
      }
    },
    {
      "chunk_id": "4f3d12bdbad39105e5f400084e0f8165",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo sys module entity USR realty no then this module in workplace studio so violation of primary key. Oh, it's because \nof data binding which does not keep correct IDs but duplicate cases module in workplace. So it's registering of a \nsection in the workplace and this duplicate is possible because of the way how data binding saves it. So we have \none data item failed to load but in general okay, one more data item failed to load so we have only troubles in couple \nof data items. But general data was loaded so we have as a result some errors. But this is because of something is \nnot exactly the same as our original stuff. Okay, let's try to reload our section. Let's see do we have anything loaded \nStudio my applications we have realty section.",
      "chunk_type": "paragraph",
      "chunk_index": 104,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 141,
      "token_count": 167,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 104
      }
    },
    {
      "chunk_id": "c4328b823ec80a82f99d6ddb4e8166c1",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nWe have classic we miss reality sections here because such data items were not loaded. I will show you how you \ncan fix it. Let's go to advanced settings. Let's find our new packages loaded here so we can search for realty \npackage and we can see couple of data items. So let's see only status has error or needs to actualize here so you \ncan see list of items that were failed to install Couple of SQL scripts from base product we don't care and only one \nitem in our reality package was not loaded. We can see error message text and properties. So violation of primary \nkey. It looks like system can't find the correct value of what and it's hard to see. Okay, let's see. So it can't find correct \nduplicate value of sys module in Workplace.",
      "chunk_type": "paragraph",
      "chunk_index": 105,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 143,
      "token_count": 172,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 105
      }
    },
    {
      "chunk_id": "369fb62c104624b3f907dc75dc1a882d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nIt looks like we already have sys module in workplace ID and it looks like this data entity was not good. So we have \nsome items here and we have key which was not ID and key was used by section and workplace. So we can fix this \nit's not good and this is behavior made by data binding tool. I don't really like it. So we can fix it with the another data \nItem organizing key by ID that will prevent the data from inserting twice with the same id so we can fix it. Let me \nshow you. Since module in Workplace in Studio so it's our reality section. This is a data item. This module in \nworkplace for Studio and such settings for key is not good ID key is better position for update if in case if record was\n\n--- Page 21 ---\n\nfound.",
      "chunk_type": "paragraph",
      "chunk_index": 106,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 106
      }
    },
    {
      "chunk_id": "2832993fcc1822f515552fff59a17cff",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nGreat, and we can save it. And we have a lot of warnings, but it's about existing date. So let's actualize it save it. Just \na lot of warnings about reorganizing of the same existing set sections that are already present in data. And also one \nmore thing which we potentially have the same trouble sys module and workplace for this realty and it's 26 my \napplication. Also it makes sense to our ID is already set here. Okay, great. Probably you can put position updates \nchoice data save it. Great, Everything is okay. So we fixed it. We have to save everything on file system just to make \nsure we will correctly have all the data well in our repository version control. So now you will see that it's possible to \nsave and load packages again. We can prepare something like order like v1 plus old file.",
      "chunk_type": "paragraph",
      "chunk_index": 107,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 151,
      "token_count": 186,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 107
      }
    },
    {
      "chunk_id": "cffff48cf240591a8a0ddf71c6e2c850",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nNow we will have a bit better version of it. Okay, saved. Now let's try to run this transport again so it will be final one. \nAnd this is example how you can automate delivery of your changes. How you can take data from developer \nenvironment and automatically save and devote it to some other task target test environment. Of course, as \ndeveloper you understand that sometimes things are not going very smoothly. Sometimes we have unexpected \nerrors. And having such errors during the training is also good because it helps us to see how you can troubleshoot, \nhow you should search for error details and how you should do all changes. So now you see next time we load it \ntook significantly less time because loader is smart.",
      "chunk_type": "paragraph",
      "chunk_index": 108,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 132,
      "token_count": 154,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 108
      }
    },
    {
      "chunk_id": "ba34a18316c5d2fccf269aae51fe36a5",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nLoader text takes zip file, takes information about its items, all the packages, all the items of configuration and it \nanalyzes date of modification. If date of modification of the loaded item is the same as date of modification of items \nthat you have already in your target environment, then it just skips it. And that's why if you have a big solution, but \nyou have tiny small changes, they are from recent upload that you did previously. It will only analyze changed items \nwhen loaded on target environment and final total installation time will be small. And now you see only couple of \ndata items that were failed were now updated and fully applied and everything else was correct. So now our system \nin our target environment has no errors. As a result of installation we can go to all packages to see items.",
      "chunk_type": "paragraph",
      "chunk_index": 109,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 171,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 109
      }
    },
    {
      "chunk_id": "baa74c96ea8e6dced453b69b7152a660",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nActually only base product stuff. Okay, don't care, no errors. Okay, so our package with realty was fully correctly \nvoided. All the items that we have were loaded well. And we can test it at our user interface. So you can go to \ncorresponding sections, you can try to create data records. You see all three actions, all three sections here. So our \nreality with columns you can create new data. So find me cat here. And you see now we have default values working. \nWe have some test data. Test price, negative price, validation works too big price will also work and system will not \nallow us to save because of server side. Okay, like this. But now you see price is more than 1 billion. So everything is \nworking as expected.",
      "chunk_type": "paragraph",
      "chunk_index": 110,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 136,
      "token_count": 174,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 110
      }
    },
    {
      "chunk_id": "af464b768aff5479de30ab49f56c873d",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo that's how you can deliver your solution to test and check it out and perform corresponding full scale test for your \nsystem to check how it works. Now you see details were filled in. So everything works quite well. And that's how you \ncan do some automation with Clio. Clio has also a lot of interest in other comments I will show you just one of them. \nClio SQL select name for contact. Okay, something like this. So this is example for Clio SQL execution. Sometimes \nwhen you work in cloud with cloud environments you just can't connect to the database directly and operate with it. \nSo sometimes you need to run some simple select queries in database to make sure you have specific data. And \nthat's how you can do it with your Clio.",
      "chunk_type": "paragraph",
      "chunk_index": 111,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 139,
      "token_count": 168,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 111
      }
    },
    {
      "chunk_id": "392195879dcbe8235f8959693307a846",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\n--- Page 22 ---\n\nSo this is example of how you can read list of contacts from your database. Of course your queries could be much \nmore complicated. And when you run SQL queries please be extremely careful because SQL statements is the way \nhow you can easily damage your system, how it can easily destroy your database. So you should be extremely \ncareful and please check your queries before execution. SQL can really help you and to see some data directly. \nUnfortunately Creature has no tools to work with SQL easily from user interface. Now previously we had such tool \nbut was designed by some Russian partner. And as you remember, as you know, Croatia gave up any work with \nRussia or Belarusian partners and customers. So we also removed all of the add ons from the marketplace.",
      "chunk_type": "paragraph",
      "chunk_index": 112,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 142,
      "token_count": 166,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 2,
        "position_in_document": 112
      }
    },
    {
      "chunk_id": "63be504cd5f3f4e2440310767d150586",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAnd that's why now we don't have any fancy good looking tool to run SQL query from application user interface. But \nnow this is something that you can do. And the last information that you need to know about Clio is that it's also \npossible to use add on for Visual Studio named Clio Explorer. So Clio Explorer Is an add on that you can use in Visual \nStudio code. It automatically loads your information from file with connections for existing solutions. And you can \nuse a lot of Clio commands from user interface including SQL. So you can do something like this. Then you can run \nyour query. Let me see where there is a button to run query. This one. So this is Clio SQL comment and it tries to run \nmy query. But what? Oh, D1. I already connected. Probably I connected. Yes. What's wrong there?",
      "chunk_type": "paragraph",
      "chunk_index": 113,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 188,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 113
      }
    },
    {
      "chunk_id": "dc84629c4f90d2292f06691402d1d8bd",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSplit editor. More actions. Oh, probably this. Yes, it was case sensitive. I don't know why it's case sensitive. But now \nyou see some data we got from the database and you have some kind of UI stuff. But with the help of Clio Explorer. \nClio Explorer uses installed Clio Explore tool. So without Clio installed it will not work. But this is user interface \nfeature which can help you to work with a particular environments. Would you like to current. No, no, no, no. Thanks. \nSo we have a lot of functions of Clio the most commonly used and some of them. And also you can use Clio \ncommands from terminal window of Visual Studio the same as we used in other Windows console bars. So, thank \nyou for your time today. Today our session is over. We will prepare for the exam tomorrow.",
      "chunk_type": "paragraph",
      "chunk_index": 114,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 148,
      "token_count": 188,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 114
      }
    },
    {
      "chunk_id": "c41993fe670da7864c4c4ff5363c4673",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nAs usual you will receive video recording of today's session. If you have any questions, ask today or prepare \nquestions for tomorrow. Because we will have more time tomorrow. Thank you very much for those who stayed for \nthis moment. You will see videos soon. Thank you and goodbye. Hi Dimitri, it's boss here. Yes boss. Please. \nTomorrow I'm. I have other obligations to attend to, so I will probably follow it by video. But is there any special \naction I have to take the fast track on development certification? Oh yeah, I will explain. So I will send you final email \nwith all video recording with homework for your fast track certification and quick explanations of what you should \ndo.",
      "chunk_type": "paragraph",
      "chunk_index": 115,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 124,
      "token_count": 154,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 115
      }
    },
    {
      "chunk_id": "0522c804ca54a3a57336804aae4fd972",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo if you agree to run Fast track certification, you should just respond to my email and we will arrange individual \ndate and time for you to run your exam. Your exam will include check of the homework. So you should prepare \nhomework before exam starts. So you will have a couple of weeks to do this and you should prepare for the test \nusing self assessment tests at Academy. I will show and so at the exam we will look at your homework and you will \nrun your online exam test. Okay. If you fail, you can run this test again later. So don't worry. It's a bit nervous. I \nunderstand. And Fast track certification is free for our guided learning participants. Okay, cool. So you will receive all \nnecessary stuff and videos explaining how to prepare for the test, how you should answer questions, and so on.",
      "chunk_type": "paragraph",
      "chunk_index": 116,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 152,
      "token_count": 182,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 116
      }
    },
    {
      "chunk_id": "4bb9d1ceeb1c5b48333f9cbb3a30ecbd",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nYou will see the type of the homework Raki is asking will include. So let me quickly show. I planned to show it\n\n--- Page 23 ---\n\ntomorrow, but okay, if you ask now. So let's do this, I will quickly show you. So the type of the homework will include \nmaking your section, this one, making your detail, make programmed validation, some calculations, web service, and \nfor those who want to run an advanced level, some additional business process and adding data records and some \nautomatic update. You can use live Update to automatically refresh your screen. Or I will show you how you can use \nWebSocket messaging if you prefer. If you prefer to do it a bit more professionally. So the homework simply is just \nsimilar to what we did during our sessions. And it requires some programming for validation, calculations and web \nservice.",
      "chunk_type": "paragraph",
      "chunk_index": 117,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 150,
      "token_count": 185,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 3,
        "position_in_document": 117
      }
    },
    {
      "chunk_id": "3b5294ddee0c3b269640ff9c2e94d987",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSo it requires some javascripting and C Sharp scripting. And so it will not take too much time for you, I think, and I \nhope that it will be clear. So we discussed all the steps how to do this. If you will have more questions, you may ask \ntomorrow. So Rakhi, I think that those who passed our sessions watched our videos and practiced with their own. \nYou can use even your own example because the name of the section is the same set of columns, very similar. So \nyou can use your training session environment to perform your homework on it. So it may be helpful. You do not \nneed to create a separate environment for your homework. Okay, thank you for your time today.",
      "chunk_type": "paragraph",
      "chunk_index": 118,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 130,
      "token_count": 156,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 118
      }
    },
    {
      "chunk_id": "2ac202112198c19e235ca921eb261aad",
      "document_id": "699402ad4f39",
      "content": "# Speaker 1\n\nSorry for staying a bit later than usual and if you will have more questions, so prepare for tomorrow, we will have \ntime for this. Thank you very much for today's session and goodbye. You will receive homework assignment \ntomorrow as well as all video recordings and all the questions I will answer tomorrow. Thank you and goodbye.",
      "chunk_type": "paragraph",
      "chunk_index": 119,
      "metadata": {
        "source_type": "pdf_transcript",
        "pdf_file": "Creatio-Developer-12.pdf"
      },
      "word_count": 61,
      "token_count": 73,
      "context": {
        "heading": "Speaker 1",
        "paragraph_count": 1,
        "position_in_document": 119
      }
    }
  ],
  "processing_timestamp": "2025-07-23T16:41:43.961738"
}